#!/usr/bin/env python3
"""
åŸç‰ˆDiscreteVAEå¯è§†åŒ–å·¥å…·
ç”¨äºå¯è§†åŒ–åŸç‰ˆdVAEæ¨¡å‹çš„è¾“å…¥è¾“å‡ºå’Œé‡å»ºç»“æœ
"""

import os
import sys
import numpy as np
import torch
import argparse
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.append(str(project_root))

from models.dvae import DiscreteVAE
from datasets.build import build_dataset_from_cfg
from utils.config import cfg_from_yaml_file
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
import matplotlib.animation as animation


class OriginalDVAEVisualizer:
    """åŸç‰ˆDiscreteVAEå¯è§†åŒ–å™¨"""
    
    def __init__(self, config_path, checkpoint_path=None, device='cuda'):
        """
        åˆå§‹åŒ–å¯è§†åŒ–å™¨
        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
            checkpoint_path: æ¨¡å‹æ£€æŸ¥ç‚¹è·¯å¾„ (å¯é€‰)
            device: è®¾å¤‡
        """
        self.device = device
        
        # åŠ è½½é…ç½®
        self.config = cfg_from_yaml_file(config_path)
        print(f"ğŸ“‹ Loaded config from {config_path}")
        
        # åˆ›å»ºæ¨¡å‹
        if hasattr(self.config, 'model'):
            model_config = self.config.model
        else:
            print("âŒ é…ç½®æ–‡ä»¶ä¸­æ²¡æœ‰modelå­—æ®µ")
            return
        
        self.model = DiscreteVAE(model_config).to(device)
        print(f"ğŸ”§ Created DiscreteVAE model:")
        print(f"   - Group size: {model_config.group_size}")
        print(f"   - Num groups: {model_config.num_group}")
        print(f"   - Total points: {model_config.group_size * model_config.num_group}")
        print(f"   - Num tokens: {model_config.num_tokens}")
        
        # åŠ è½½æ£€æŸ¥ç‚¹
        if checkpoint_path and os.path.exists(checkpoint_path):
            checkpoint = torch.load(checkpoint_path, map_location=device)
            if 'model' in checkpoint:
                self.model.load_state_dict(checkpoint['model'])
            else:
                self.model.load_state_dict(checkpoint)
            print(f"âœ… Loaded model from {checkpoint_path}")
        else:
            print("âš ï¸ No checkpoint loaded, using random weights")
        
        self.model.eval()
    
    def visualize_single_sample(self, data_sample, save_path=None):
        """
        å¯è§†åŒ–å•ä¸ªæ ·æœ¬çš„é‡å»ºç»“æœ
        Args:
            data_sample: (N, 3) ç‚¹äº‘æ•°æ®
            save_path: ä¿å­˜è·¯å¾„
        """
        if isinstance(data_sample, np.ndarray):
            data_sample = torch.from_numpy(data_sample).float()
        
        # æ·»åŠ æ‰¹æ¬¡ç»´åº¦
        if len(data_sample.shape) == 2:
            data_sample = data_sample.unsqueeze(0)  # (1, N, 3)
        
        data_sample = data_sample.to(self.device)
        
        with torch.no_grad():
            # åŸç‰ˆdVAEå‰å‘ä¼ æ’­
            # è¿”å›æ ¼å¼: whole_coarse, whole_fine, coarse, fine, group_gt, kl_loss
            ret = self.model(data_sample, temperature=0.1, hard=False)
            
            whole_coarse, whole_fine, coarse, fine, group_gt, kl_loss = ret
        
        # è½¬æ¢ä¸ºnumpy
        original = data_sample[0].cpu().numpy()  # (N, 3)
        whole_coarse_np = whole_coarse[0].cpu().numpy()  # (N, 3) 
        whole_fine_np = whole_fine[0].cpu().numpy()  # (N, 3)
        
        # coarseå’Œfineæ˜¯åˆ†ç»„æ ¼å¼ (batch, num_group, group_size, 3)
        # éœ€è¦é‡æ–°æ•´å½¢
        bs, num_group, group_size, _ = coarse.shape
        coarse_reshaped = coarse.view(bs, -1, 3)[0].cpu().numpy()  # (num_group*group_size, 3)
        fine_reshaped = fine.view(bs, -1, 3)[0].cpu().numpy()  # (num_group*group_size, 3)
        
        # åˆ›å»ºå¯è§†åŒ–
        fig = plt.figure(figsize=(20, 12))
        
        # 1. åŸå§‹ç‚¹äº‘
        ax1 = fig.add_subplot(231, projection='3d')
        self._plot_point_cloud(ax1, original, title=f'Original ({original.shape[0]} points)', color='blue')
        
        # 2. Whole Coarse (ç²—ç•¥é‡å»º)
        ax2 = fig.add_subplot(232, projection='3d')
        self._plot_point_cloud(ax2, whole_coarse_np, title=f'Whole Coarse ({whole_coarse_np.shape[0]} points)', color='orange')
        
        # 3. Whole Fine (ç²¾ç»†é‡å»º)
        ax3 = fig.add_subplot(233, projection='3d')
        self._plot_point_cloud(ax3, whole_fine_np, title=f'Whole Fine ({whole_fine_np.shape[0]} points)', color='green')
        
        # 4. åˆ†ç»„Coarse
        ax4 = fig.add_subplot(234, projection='3d')
        self._plot_grouped_points(ax4, coarse_reshaped, num_group, group_size, 
                                 title=f'Grouped Coarse ({num_group}Ã—{group_size} points)')
        
        # 5. åˆ†ç»„Fine
        ax5 = fig.add_subplot(235, projection='3d')
        self._plot_grouped_points(ax5, fine_reshaped, num_group, group_size,
                                 title=f'Grouped Fine ({num_group}Ã—{group_size} points)')
        
        # 6. å¯¹æ¯”å›¾
        ax6 = fig.add_subplot(236, projection='3d')
        self._plot_comparison(ax6, original, whole_fine_np, title='Original vs Fine Reconstruction')
        
        plt.tight_layout()
        
        if save_path:
            os.makedirs(os.path.dirname(save_path), exist_ok=True)
            plt.savefig(save_path, dpi=150, bbox_inches='tight')
            print(f"ğŸ’¾ Saved visualization to {save_path}")
        
        plt.show()
        
        # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
        mse_whole_fine = np.mean((original - whole_fine_np) ** 2)
        kl_loss_value = kl_loss.mean().item() if kl_loss is not None else 0.0
        
        print(f"ğŸ“Š Reconstruction Statistics:")
        print(f"   MSE (Original vs Whole Fine): {mse_whole_fine:.6f}")
        print(f"   KL Loss: {kl_loss_value:.6f}")
        print(f"ğŸ”§ Model Info:")
        print(f"   Groups: {num_group}, Group size: {group_size}")
        print(f"   Total reconstructed points: {num_group * group_size}")
        
        return {
            'original': original,
            'whole_coarse': whole_coarse_np,
            'whole_fine': whole_fine_np,
            'coarse_grouped': coarse_reshaped,
            'fine_grouped': fine_reshaped,
            'mse_whole_fine': mse_whole_fine,
            'kl_loss': kl_loss_value
        }
    
    def _plot_point_cloud(self, ax, points, title, color='blue', size=20):
        """ç»˜åˆ¶ç‚¹äº‘"""
        ax.scatter(points[:, 0], points[:, 1], points[:, 2], 
                  c=color, s=size, alpha=0.6)
        
        ax.set_title(title, fontsize=12, fontweight='bold')
        ax.set_xlabel('X')
        ax.set_ylabel('Y')
        ax.set_zlabel('Z')
        
        # è®¾ç½®ç›¸åŒçš„åæ ‡èŒƒå›´
        all_points = points.reshape(-1, 3)
        max_range = np.max(np.abs(all_points)) * 1.1 if all_points.size > 0 else 1.0
        ax.set_xlim([-max_range, max_range])
        ax.set_ylim([-max_range, max_range])
        ax.set_zlim([-max_range, max_range])
    
    def _plot_grouped_points(self, ax, points, num_group, group_size, title):
        """ç»˜åˆ¶åˆ†ç»„ç‚¹äº‘ï¼Œä¸åŒç»„ç”¨ä¸åŒé¢œè‰²"""
        colors = plt.cm.tab20(np.linspace(0, 1, num_group))
        
        for g in range(num_group):
            start_idx = g * group_size
            end_idx = start_idx + group_size
            if end_idx <= len(points):
                group_points = points[start_idx:end_idx]
                ax.scatter(group_points[:, 0], group_points[:, 1], group_points[:, 2],
                          c=[colors[g]], s=30, alpha=0.7, label=f'Group {g+1}')
        
        ax.set_title(title, fontsize=12, fontweight='bold')
        ax.set_xlabel('X')
        ax.set_ylabel('Y') 
        ax.set_zlabel('Z')
        
        # è®¾ç½®ç›¸åŒçš„åæ ‡èŒƒå›´
        if len(points) > 0:
            max_range = np.max(np.abs(points)) * 1.1
            ax.set_xlim([-max_range, max_range])
            ax.set_ylim([-max_range, max_range])
            ax.set_zlim([-max_range, max_range])
    
    def _plot_comparison(self, ax, original, reconstructed, title):
        """ç»˜åˆ¶åŸå§‹å’Œé‡å»ºçš„å¯¹æ¯”"""
        ax.scatter(original[:, 0], original[:, 1], original[:, 2],
                  c='blue', s=20, alpha=0.5, label='Original')
        ax.scatter(reconstructed[:, 0], reconstructed[:, 1], reconstructed[:, 2],
                  c='red', s=15, alpha=0.7, label='Reconstructed')
        
        ax.set_title(title, fontsize=12, fontweight='bold')
        ax.set_xlabel('X')
        ax.set_ylabel('Y')
        ax.set_zlabel('Z')
        ax.legend()
        
        # è®¾ç½®ç›¸åŒçš„åæ ‡èŒƒå›´
        all_points = np.vstack([original, reconstructed])
        if len(all_points) > 0:
            max_range = np.max(np.abs(all_points)) * 1.1
            ax.set_xlim([-max_range, max_range])
            ax.set_ylim([-max_range, max_range])
            ax.set_zlim([-max_range, max_range])

    def visualize_dataset_samples(self, num_samples=3, save_dir=None):
        """å¯è§†åŒ–æ•°æ®é›†æ ·æœ¬"""
        # ç›´æ¥åˆ›å»ºMMFIæ•°æ®é›†å®ä¾‹
        try:
            if hasattr(self.config, 'dataset') and hasattr(self.config.dataset, 'train'):
                dataset_config = self.config.dataset.train
                # å¤„ç†_base_å¼•ç”¨
                dataset_config = self._build_dataset_config(dataset_config)
            else:
                print("âš ï¸ No dataset config found, using default MMFI config")
                dataset_config = self._dict_to_namespace({
                    'NAME': 'MMFI',
                    'DATA_PATH': 'data/MMFI',
                    'N_POINTS': 650,
                    'subset': 'train',
                    'npoints': self.config.model.group_size * self.config.model.num_group  # è®¾ç½®ç›®æ ‡ç‚¹æ•°
                })
            
            from datasets.MMFIDataset import MMFIDataset
            dataset = MMFIDataset(dataset_config)
            print(f"ğŸ“¦ Dataset size: {len(dataset)}")
            
        except Exception as e:
            print(f"âŒ Failed to create dataset: {e}")
            return []
        
        if save_dir:
            os.makedirs(save_dir, exist_ok=True)
        
        results = []
        for i in range(min(num_samples, len(dataset))):
            print(f"\nğŸ” Processing sample {i+1}/{num_samples}")
            
            # è·å–æ•°æ®æ ·æœ¬
            data = dataset[i]
            if isinstance(data, (list, tuple)) and len(data) >= 2:
                points = data[2] if len(data) > 2 else data[1]
            else:
                points = data
            
            print(f"ğŸ“ Sample shape: {points.shape}")
            
            # å¯è§†åŒ–
            save_path = os.path.join(save_dir, f'original_dvae_sample_{i+1}.png') if save_dir else None
            result = self.visualize_single_sample(points, save_path)
            results.append(result)
        
        # ç»Ÿè®¡ä¿¡æ¯
        mse_values = [r['mse_whole_fine'] for r in results]
        kl_values = [r['kl_loss'] for r in results]
        
        print(f"\nğŸ“ˆ Reconstruction Statistics (Average):")
        print(f"   Mean MSE: {np.mean(mse_values):.6f}")
        print(f"   Std MSE:  {np.std(mse_values):.6f}")
        print(f"   Mean KL:  {np.mean(kl_values):.6f}")
        print(f"   Std KL:   {np.std(kl_values):.6f}")
        
        return results
    
    def _build_dataset_config(self, dataset_config):
        """æ„å»ºæ•°æ®é›†é…ç½®ï¼Œå¤„ç†_base_å¼•ç”¨"""
        if hasattr(dataset_config, '_base_'):
            base_config = dataset_config._base_
            config_dict = {}
            
            if hasattr(base_config, '__dict__'):
                config_dict.update(base_config.__dict__)
            else:
                config_dict.update(base_config)
            
            if hasattr(dataset_config, 'others'):
                if hasattr(dataset_config.others, '__dict__'):
                    config_dict.update(dataset_config.others.__dict__)
                else:
                    config_dict.update(dataset_config.others)
            
            return self._dict_to_namespace(config_dict)
        else:
            return dataset_config
    
    def _dict_to_namespace(self, config_dict):
        """å°†å­—å…¸è½¬æ¢ä¸ºå…·æœ‰å±æ€§è®¿é—®çš„å¯¹è±¡"""
        from types import SimpleNamespace
        
        if isinstance(config_dict, dict):
            namespace = SimpleNamespace()
            for key, value in config_dict.items():
                if isinstance(value, dict):
                    setattr(namespace, key, self._dict_to_namespace(value))
                else:
                    setattr(namespace, key, value)
            return namespace
        else:
            return config_dict


def main():
    parser = argparse.ArgumentParser(description='Original DiscreteVAE Visualization Tool')
    parser.add_argument('--config', type=str, required=True,
                       help='Path to config file')
    parser.add_argument('--checkpoint', type=str,
                       help='Path to model checkpoint')
    parser.add_argument('--num_samples', type=int, default=3,
                       help='Number of samples to visualize')
    parser.add_argument('--save_dir', type=str, default='./visualizations/original_dvae',
                       help='Save directory for outputs')
    parser.add_argument('--device', type=str, default='cuda',
                       help='Device to use')
    
    args = parser.parse_args()
    
    # åˆ›å»ºå¯è§†åŒ–å™¨
    visualizer = OriginalDVAEVisualizer(
        config_path=args.config,
        checkpoint_path=args.checkpoint,
        device=args.device
    )
    
    # å¯è§†åŒ–æ•°æ®é›†æ ·æœ¬
    print(f"ğŸ¨ Visualizing {args.num_samples} dataset samples...")
    visualizer.visualize_dataset_samples(
        num_samples=args.num_samples,
        save_dir=args.save_dir
    )


if __name__ == '__main__':
    main()
