#!/usr/bin/env python3
"""
GCNSkeletonTokenizer è®­ç»ƒç¯å¢ƒæ£€æŸ¥è„šæœ¬
æ£€æŸ¥è®­ç»ƒæ‰€éœ€çš„æ‰€æœ‰æ–‡ä»¶å’Œé…ç½®æ˜¯å¦æ­£ç¡®
"""

import os
import sys
import importlib.util
from pathlib import Path

def check_file_exists(filepath, description=""):
    """æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨"""
    if os.path.exists(filepath):
        print(f"âœ… {filepath} {description}")
        return True
    else:
        print(f"âŒ {filepath} {description} - æ–‡ä»¶ä¸å­˜åœ¨")
        return False

def check_import(module_name, description=""):
    """æ£€æŸ¥æ¨¡å—æ˜¯å¦å¯ä»¥å¯¼å…¥"""
    try:
        importlib.import_module(module_name)
        print(f"âœ… {module_name} {description}")
        return True
    except Exception as e:
        print(f"âŒ {module_name} {description} - å¯¼å…¥å¤±è´¥: {e}")
        return False

def check_training_environment():
    """æ£€æŸ¥è®­ç»ƒç¯å¢ƒ"""
    print("=" * 60)
    print("GCNSkeletonTokenizer è®­ç»ƒç¯å¢ƒæ£€æŸ¥")
    print("=" * 60)
    
    success_count = 0
    total_checks = 0
    
    # 1. æ£€æŸ¥æ ¸å¿ƒè®­ç»ƒæ–‡ä»¶
    print("\nğŸ“‹ 1. æ ¸å¿ƒè®­ç»ƒæ–‡ä»¶æ£€æŸ¥:")
    core_files = [
        ("main.py", "ä¸»è®­ç»ƒè„šæœ¬"),
        ("cfgs/NTU_models/gcn_skeleton_memory_optimized.yaml", "æ¨¡å‹é…ç½®æ–‡ä»¶"),
        ("cfgs/dataset_configs/NTU_skeleton_raw.yaml", "æ•°æ®é›†é…ç½®æ–‡ä»¶"),
        ("models/GCNSkeletonTokenizer.py", "GCNéª¨æ¶Tokenizeræ¨¡å‹"),
    ]
    
    for filepath, desc in core_files:
        total_checks += 1
        if check_file_exists(filepath, desc):
            success_count += 1
    
    # 2. æ£€æŸ¥è®­ç»ƒå·¥å…·æ–‡ä»¶
    print("\nğŸ”§ 2. è®­ç»ƒå·¥å…·æ–‡ä»¶æ£€æŸ¥:")
    tool_files = [
        ("tools/__init__.py", "å·¥å…·åŒ…åˆå§‹åŒ–"),
        ("tools/runner.py", "è®­ç»ƒå¾ªç¯é€»è¾‘"),
        ("tools/builder.py", "æ¨¡å‹å’Œæ•°æ®é›†æ„å»º"),
    ]
    
    for filepath, desc in tool_files:
        total_checks += 1
        if check_file_exists(filepath, desc):
            success_count += 1
    
    # 3. æ£€æŸ¥æ•°æ®é›†æ–‡ä»¶
    print("\nğŸ“Š 3. æ•°æ®é›†æ–‡ä»¶æ£€æŸ¥:")
    dataset_files = [
        ("datasets/__init__.py", "æ•°æ®é›†åŒ…åˆå§‹åŒ–"),
        ("datasets/build.py", "æ•°æ®é›†æ„å»ºå‡½æ•°"),
        ("datasets/NTUDataset.py", "NTUæ•°æ®é›†åŠ è½½å™¨"),
        ("datasets/NTUSkeletonRawDataset.py", "åŸå§‹éª¨æ¶æ•°æ®åŠ è½½å™¨"),
        ("datasets/data_transforms.py", "æ•°æ®å˜æ¢"),
        ("datasets/io.py", "æ•°æ®IOå·¥å…·"),
    ]
    
    for filepath, desc in dataset_files:
        total_checks += 1
        if check_file_exists(filepath, desc):
            success_count += 1
    
    # 4. æ£€æŸ¥å·¥å…·åº“æ–‡ä»¶
    print("\nğŸ› ï¸ 4. å·¥å…·åº“æ–‡ä»¶æ£€æŸ¥:")
    util_files = [
        ("utils/config.py", "é…ç½®æ–‡ä»¶è§£æ"),
        ("utils/parser.py", "å‘½ä»¤è¡Œå‚æ•°è§£æ"),
        ("utils/logger.py", "æ—¥å¿—å·¥å…·"),
        ("utils/misc.py", "æ‚é¡¹å·¥å…·"),
        ("utils/dist_utils.py", "åˆ†å¸ƒå¼è®­ç»ƒå·¥å…·"),
        ("utils/AverageMeter.py", "æŒ‡æ ‡è®¡ç®—"),
        ("utils/metrics.py", "è¯„ä¼°æŒ‡æ ‡"),
    ]
    
    for filepath, desc in util_files:
        total_checks += 1
        if check_file_exists(filepath, desc):
            success_count += 1
    
    # 5. æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
    print("\nğŸ§  5. æ¨¡å‹ç›¸å…³æ–‡ä»¶æ£€æŸ¥:")
    model_files = [
        ("models/__init__.py", "æ¨¡å‹åŒ…åˆå§‹åŒ–"),
        ("models/build.py", "æ¨¡å‹æ„å»ºå·¥å…·"),
        ("models/Tokenizer.py", "åŸºç¡€Tokenizer"),
        ("models/dvae.py", "DVAEæ¨¡å‹"),
    ]
    
    for filepath, desc in model_files:
        total_checks += 1
        if check_file_exists(filepath, desc):
            success_count += 1
    
    # 6. æ£€æŸ¥Pythonæ¨¡å—å¯¼å…¥
    print("\nğŸ 6. Pythonæ¨¡å—å¯¼å…¥æ£€æŸ¥:")
    import_tests = [
        ("tools", "è®­ç»ƒå·¥å…·åŒ…"),
        ("utils.config", "é…ç½®è§£æ"),
        ("utils.parser", "å‚æ•°è§£æ"),
        ("datasets", "æ•°æ®é›†åŒ…"),
        ("models", "æ¨¡å‹åŒ…"),
    ]
    
    for module, desc in import_tests:
        total_checks += 1
        if check_import(module, desc):
            success_count += 1
    
    # 7. æ£€æŸ¥å…³é”®é…ç½®
    print("\nâš™ï¸ 7. é…ç½®æ–‡ä»¶å†…å®¹æ£€æŸ¥:")
    try:
        # æ£€æŸ¥æ¨¡å‹é…ç½®
        import yaml
        with open("cfgs/NTU_models/gcn_skeleton_memory_optimized.yaml", 'r') as f:
            model_config = yaml.safe_load(f)
        
        if model_config.get('model', {}).get('NAME') == 'GCNSkeletonTokenizer':
            print("âœ… æ¨¡å‹é…ç½®æ­£ç¡®: GCNSkeletonTokenizer")
            success_count += 1
        else:
            print("âŒ æ¨¡å‹é…ç½®é”™è¯¯: æœªæ‰¾åˆ°GCNSkeletonTokenizer")
        total_checks += 1
        
        # æ£€æŸ¥æ•°æ®é›†é…ç½®
        with open("cfgs/dataset_configs/NTU_skeleton_raw.yaml", 'r') as f:
            dataset_config = yaml.safe_load(f)
        
        if dataset_config.get('NAME') == 'NTU_Skeleton_Raw':
            print("âœ… æ•°æ®é›†é…ç½®æ­£ç¡®: NTU_Skeleton_Raw")
            success_count += 1
        else:
            print("âŒ æ•°æ®é›†é…ç½®é”™è¯¯: æœªæ‰¾åˆ°NTU_Skeleton_Raw")
        total_checks += 1
        
    except Exception as e:
        print(f"âŒ é…ç½®æ–‡ä»¶æ£€æŸ¥å¤±è´¥: {e}")
        total_checks += 2
    
    # 8. æ£€æŸ¥æ•°æ®è·¯å¾„
    print("\nğŸ“ 8. æ•°æ®è·¯å¾„æ£€æŸ¥:")
    data_path = "../HumanPoint-BERT/data/NTU-RGB+D"
    total_checks += 1
    if os.path.exists(data_path):
        print(f"âœ… æ•°æ®è·¯å¾„å­˜åœ¨: {data_path}")
        success_count += 1
        
        # æ£€æŸ¥æ•°æ®æ–‡ä»¶
        skeleton_files = [f for f in os.listdir(data_path) if f.endswith('.skeleton') or 'skeleton' in f]
        if skeleton_files:
            print(f"âœ… æ‰¾åˆ° {len(skeleton_files)} ä¸ªéª¨æ¶æ•°æ®æ–‡ä»¶")
        else:
            print("âš ï¸ æœªæ‰¾åˆ°.skeletonæ–‡ä»¶ï¼Œå¯èƒ½éœ€è¦è§£å‹æ•°æ®")
    else:
        print(f"âŒ æ•°æ®è·¯å¾„ä¸å­˜åœ¨: {data_path}")
        print("   è¯·ç¡®ä¿NTU RGB+Dæ•°æ®é›†å·²ä¸‹è½½å¹¶æ”¾ç½®åœ¨æ­£ç¡®ä½ç½®")
    
    # 9. ç”Ÿæˆè®­ç»ƒå‘½ä»¤
    print("\nğŸš€ 9. æ¨èè®­ç»ƒå‘½ä»¤:")
    print("åŸºæœ¬è®­ç»ƒå‘½ä»¤:")
    print("  python main.py --config cfgs/NTU_models/gcn_skeleton_memory_optimized.yaml")
    print("\nå¸¦GPUæŒ‡å®š:")
    print("  python main.py --config cfgs/NTU_models/gcn_skeleton_memory_optimized.yaml --gpu 0")
    print("\næµ‹è¯•æ¨¡å¼:")
    print("  python main.py --config cfgs/NTU_models/gcn_skeleton_memory_optimized.yaml --test --ckpts path/to/checkpoint.pth")
    
    # 10. æ€»ç»“
    print("\n" + "=" * 60)
    print("æ£€æŸ¥æ€»ç»“:")
    print(f"æ€»æ£€æŸ¥é¡¹: {total_checks}")
    print(f"é€šè¿‡é¡¹: {success_count}")
    print(f"å¤±è´¥é¡¹: {total_checks - success_count}")
    print(f"é€šè¿‡ç‡: {success_count/total_checks*100:.1f}%")
    
    if success_count == total_checks:
        print("\nğŸ‰ æ‰€æœ‰æ£€æŸ¥é€šè¿‡ï¼å¯ä»¥å¼€å§‹è®­ç»ƒäº†ï¼")
        return True
    elif success_count >= total_checks * 0.8:
        print("\nâš ï¸ å¤§éƒ¨åˆ†æ£€æŸ¥é€šè¿‡ï¼Œå¯ä»¥å°è¯•è®­ç»ƒï¼Œä½†å¯èƒ½é‡åˆ°é—®é¢˜")
        return False
    else:
        print("\nâŒ å¤šä¸ªå…³é”®æ–‡ä»¶ç¼ºå¤±ï¼Œè¯·å…ˆè§£å†³è¿™äº›é—®é¢˜")
        return False

def show_training_tips():
    """æ˜¾ç¤ºè®­ç»ƒæŠ€å·§"""
    print("\n" + "=" * 60)
    print("ğŸ’¡ è®­ç»ƒæŠ€å·§æç¤º:")
    print("=" * 60)
    
    tips = [
        "1. é¦–æ¬¡è®­ç»ƒå»ºè®®ä½¿ç”¨å°æ‰¹æ¬¡å¤§å°(bs=4)é¿å…æ˜¾å­˜ä¸è¶³",
        "2. ä½¿ç”¨TensorBoardç›‘æ§è®­ç»ƒè¿‡ç¨‹: tensorboard --logdir experiments/",
        "3. è®­ç»ƒæ—¥å¿—ä¿å­˜åœ¨ experiments/gcn_skeleton_memory_optimized/logs/",
        "4. æ¨¡å‹æ£€æŸ¥ç‚¹ä¿å­˜åœ¨ experiments/gcn_skeleton_memory_optimized/checkpoints/",
        "5. å¦‚é‡åˆ°æ•°æ®åŠ è½½æ…¢ï¼Œå¯è®¾ç½® num_workers=0 è¿›è¡Œè°ƒè¯•",
        "6. VQæŸå¤±å’Œé‡å»ºæŸå¤±çš„æƒé‡å¯åœ¨é…ç½®æ–‡ä»¶ä¸­è°ƒæ•´",
        "7. æ”¯æŒä»æ£€æŸ¥ç‚¹ç»§ç»­è®­ç»ƒ: --resume --ckpts path/to/checkpoint.pth",
    ]
    
    for tip in tips:
        print(f"  {tip}")
    
    print("\nğŸ“š æ›´å¤šå¸®åŠ©æ–‡æ¡£:")
    print("  - docs/GCNSkeletonTokenizer_Training_Guide.md")
    print("  - docs/GCNSkeletonTokenizer_Usage_Guide.md")
    print("  - docs/GCNSkeletonTokenizer_Config_Examples.md")

def main():
    """ä¸»å‡½æ•°"""
    # åˆ‡æ¢åˆ°é¡¹ç›®æ ¹ç›®å½•
    script_dir = Path(__file__).parent
    project_root = script_dir.parent
    os.chdir(project_root)
    
    print(f"å½“å‰å·¥ä½œç›®å½•: {os.getcwd()}")
    
    # æ‰§è¡Œç¯å¢ƒæ£€æŸ¥
    success = check_training_environment()
    
    # æ˜¾ç¤ºè®­ç»ƒæŠ€å·§
    show_training_tips()
    
    return success

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)