#!/usr/bin/env python3
"""
éª¨æ¶æå– + GCNé‡æ„å®Œæ•´æµç¨‹
ç»“åˆskeleton_extractor.pyçš„é›·è¾¾éª¨æ¶æå–å’ŒGCNSkeletonTokenizer.pyçš„éª¨æ¶é‡æ„
å®ç°é›·è¾¾ä¿¡å· â†’ éª¨æ¶æå– â†’ ç æœ¬ç¼–ç  â†’ é‡æ„å¯è§†åŒ–çš„å®Œæ•´ç®¡çº¿
"""

import os
import sys
import torch
import numpy as np
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
from pathlib import Path
import cv2
from PIL import Image
import io
from matplotlib.animation import FuncAnimation, PillowWriter

# è®¾ç½®matplotlib
import matplotlib
matplotlib.use('Agg')

# æ·»åŠ modelsè·¯å¾„ä»¥å¯¼å…¥å…³èŠ‚ç‚¹æ˜ å°„å™¨
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))
from models.skeleton_joint_mapper import SkeletonJointMapper, EnhancedSkeletonMapper

# é…ç½®ä¸­æ–‡å­—ä½“æ”¯æŒ
plt.rcParams['font.sans-serif'] = ['DejaVu Sans', 'SimHei', 'Arial Unicode MS', 'Droid Sans Fallback']
plt.rcParams['axes.unicode_minus'] = False
plt.rcParams['font.size'] = 10

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.append(str(project_root))

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
try:
    from models.skeleton_extractor import MARSTransformerModel
    from models.GCNSkeletonTokenizer import GCNSkeletonTokenizer
    from utils.config import cfg_from_yaml_file
except ImportError as e:
    print(f"Import error: {e}")
    sys.exit(1)

class SkeletonExtractionReconstructionPipeline:
    """éª¨æ¶æå–å’Œé‡æ„å®Œæ•´æµç¨‹"""
    
    def __init__(self, extractor_model_path, gcn_model_path, gcn_config_path, use_enhanced_mapping=True):
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        print(f"Using device: {self.device}")
        
        # åˆå§‹åŒ–å…³èŠ‚ç‚¹æ˜ å°„å™¨ (MARS 19å…³èŠ‚ -> NTU 25å…³èŠ‚)
        if use_enhanced_mapping:
            self.joint_mapper = EnhancedSkeletonMapper().to(self.device)
            print("ğŸ¯ ä½¿ç”¨å¢å¼ºå…³èŠ‚ç‚¹æ˜ å°„å™¨ (MARS 19å…³èŠ‚ -> NTU 25å…³èŠ‚)")
        else:
            self.joint_mapper = SkeletonJointMapper().to(self.device)
            print("ğŸ¯ ä½¿ç”¨åŸºç¡€å…³èŠ‚ç‚¹æ˜ å°„å™¨ (MARS 19å…³èŠ‚ -> NTU 25å…³èŠ‚)")
        
        # åŠ è½½éª¨æ¶æå–å™¨
        self.skeleton_extractor = self._load_skeleton_extractor(extractor_model_path)
        
        # åŠ è½½GCNé‡æ„å™¨
        self.gcn_reconstructor = self._load_gcn_reconstructor(gcn_model_path, gcn_config_path)
        
        # NTU RGB+D 25å…³èŠ‚ç‚¹è¿æ¥å…³ç³»
        self.skeleton_edges = [
            (3, 2), (2, 20), (20, 1), (1, 0),  # å¤´éƒ¨å’Œè„ŠæŸ±
            (20, 4), (4, 5), (5, 6), (6, 22), (6, 7), (7, 21),  # å·¦è‡‚
            (20, 8), (8, 9), (9, 10), (10, 24), (10, 11), (11, 23),  # å³è‡‚
            (0, 12), (12, 13), (13, 14), (14, 15),  # å·¦è…¿
            (0, 16), (16, 17), (17, 18), (18, 19)   # å³è…¿
        ]
    
    def _load_skeleton_extractor(self, model_path):
        """åŠ è½½MARSéª¨æ¶æå–å™¨"""
        print(f"Loading skeleton extractor: {model_path}")
        
        # åˆ›å»ºæ¨¡å‹
        model = MARSTransformerModel(input_channels=5, output_dim=57)
        
        # åŠ è½½æƒé‡
        state_dict = torch.load(model_path, map_location=self.device)
        model.load_state_dict(state_dict)
        model.to(self.device)
        model.eval()
        
        print("âœ… Skeleton extractor loaded successfully!")
        return model
    
    def _load_gcn_reconstructor(self, model_path, config_path):
        """åŠ è½½GCNéª¨æ¶é‡æ„å™¨"""
        print(f"Loading GCN reconstructor: {model_path}")
        
        # åŠ è½½é…ç½®
        config = cfg_from_yaml_file(config_path)
        
        # åˆ›å»ºæ¨¡å‹
        model = GCNSkeletonTokenizer(config.model)
        
        # åŠ è½½æƒé‡
        checkpoint = torch.load(model_path, map_location=self.device)
        
        if 'base_model' in checkpoint:
            state_dict = checkpoint['base_model']
        else:
            state_dict = checkpoint
            
        # å¤„ç†åˆ†å¸ƒå¼è®­ç»ƒæƒé‡
        new_state_dict = {}
        for k, v in state_dict.items():
            if k.startswith('module.'):
                new_state_dict[k[7:]] = v
            else:
                new_state_dict[k] = v
        
        model.load_state_dict(new_state_dict)
        model.to(self.device)
        model.eval()
        
        print("âœ… GCN reconstructor loaded successfully!")
        return model
    
    def extract_skeleton_from_radar(self, radar_data):
        """ä»é›·è¾¾ç‰¹å¾å›¾æå–éª¨æ¶"""
        with torch.no_grad():
            # è½¬æ¢æ•°æ®æ ¼å¼ï¼š(B, H, W, C) -> (B, C, H, W)
            if len(radar_data.shape) == 4:
                radar_tensor = torch.from_numpy(radar_data.transpose(0, 3, 1, 2)).float().to(self.device)
            elif len(radar_data.shape) == 3:
                radar_tensor = torch.from_numpy(radar_data.transpose(2, 0, 1)).unsqueeze(0).float().to(self.device)
            else:
                raise ValueError(f"Unexpected radar data shape: {radar_data.shape}")
            
            # MARSéª¨æ¶æå–å™¨æ¨ç†
            mars_output = self.skeleton_extractor(radar_tensor)
            
            # æ£€æŸ¥è¾“å‡ºæ ¼å¼
            if len(mars_output.shape) == 2 and mars_output.shape[1] == 57:
                # MARSæ ¼å¼ï¼š(B, 57) = (x1...x19, y1...y19, z1...z19)
                # å‚ç…§vis_skeleton_extractor.pyçš„å¤„ç†æ–¹å¼
                batch_size = mars_output.shape[0]
                
                # é‡ç»„ä¸º(B, 19, 3)æ ¼å¼: ä»æ‰å¹³åŒ–çš„57ç»´é‡ç»„ä¸º19ä¸ªå…³èŠ‚ç‚¹
                x_coords = mars_output[:, 0:19]    # xåæ ‡: 0-18
                y_coords = mars_output[:, 19:38]   # yåæ ‡: 19-37  
                z_coords = mars_output[:, 38:57]   # zåæ ‡: 38-56
                mars_skeleton = torch.stack([x_coords, y_coords, z_coords], dim=-1)  # (B, 19, 3)
            else:
                # å‡è®¾å·²ç»æ˜¯(B, 19, 3)æ ¼å¼
                mars_skeleton = mars_output
            
            # ä½¿ç”¨æ˜ å°„å™¨è½¬æ¢ä¸ºNTU 25å…³èŠ‚ç‚¹
            # æ³¨æ„ï¼šæ˜ å°„å™¨éœ€è¦åŸå§‹57ç»´è¾“å‡ºï¼Œä¼šå†…éƒ¨å¤„ç†åæ ‡é‡ç»„
            ntu_skeleton = self.joint_mapper(mars_output)  # ä¼ å…¥åŸå§‹57ç»´è¾“å‡º
            
            return ntu_skeleton
    
    def reconstruct_skeleton_with_gcn(self, skeleton_data):
        """ä½¿ç”¨GCNç æœ¬é‡æ„éª¨æ¶"""
        with torch.no_grad():
            # æ ‡å‡†åŒ–éª¨æ¶æ•°æ®ï¼ˆä¸GCNè®­ç»ƒæ—¶ä¸€è‡´ï¼‰
            normalized_skeleton = self._normalize_skeleton(skeleton_data)
            
            # è½¬æ¢ä¸ºå¼ é‡
            if isinstance(normalized_skeleton, np.ndarray):
                skeleton_tensor = torch.from_numpy(normalized_skeleton.astype(np.float32))
            else:
                skeleton_tensor = normalized_skeleton
            
            skeleton_tensor = skeleton_tensor.to(self.device)
            
            # GCNå‰å‘ä¼ æ’­
            output = self.gcn_reconstructor(skeleton_tensor, return_recon=True)
            
            # æå–ç»“æœ
            reconstructed_xzy = output['reconstructed'].cpu().numpy()
            token_sequence = output['token_sequence'].cpu().numpy()
            vq_loss = output['vq_loss'].item()
            
            # å‚ç…§gcn_skeleton_gif_visualizer.pyçš„å¤„ç†æ–¹å¼ï¼š
            # å¯¹é‡å»ºçš„éª¨æ¶è¿›è¡Œåæ ‡è½¬æ¢: (x,z,y) -> (x,y,z) ä»¥åŒ¹é…å¯è§†åŒ–
            reconstructed = reconstructed_xzy[:, :, [0, 2, 1]]  # [x,z,y] -> [x,y,z]
            
            # å°†å½’ä¸€åŒ–ç»“æœä¹Ÿè½¬æ¢å›(x,y,z)æ ¼å¼ä»¥ä¿æŒä¸€è‡´æ€§
            # normalized_skeletonç°åœ¨æ˜¯(x,z,y)æ ¼å¼ï¼Œéœ€è¦è½¬æ¢ä¸º(x,y,z)
            normalized_xyz = normalized_skeleton[:, :, [0, 2, 1]]  # [x,z,y] -> [x,y,z]
            
            return {
                'original': skeleton_data,
                'normalized': normalized_xyz,
                'reconstructed': reconstructed,
                'token_sequence': token_sequence,
                'vq_loss': vq_loss,
                'group_results': output.get('group_results', {})
            }
    
    def _normalize_skeleton(self, skeleton):
        """æ ‡å‡†åŒ–éª¨æ¶æ•°æ®ï¼ˆä¸GCNè®­ç»ƒæ—¶ä¿æŒä¸€è‡´ï¼‰
        
        å‚è€ƒgcn_skeleton_gif_visualizer.pyçš„å¤„ç†æ–¹å¼ï¼š
        - è¾“å…¥ï¼šå¯è§†åŒ–æ ¼å¼çš„(x,y,z)éª¨æ¶æ•°æ®  
        - è½¬æ¢ï¼šä¸ºGCNæ¨¡å‹æ¨ç†è½¬æ¢ä¸º(x,z,y)æ ¼å¼
        - æ ‡å‡†åŒ–ï¼šä½¿ç”¨ä¸è®­ç»ƒæ—¶ä¸€è‡´çš„æ–¹æ³•
        """
        if isinstance(skeleton, torch.Tensor):
            skeleton = skeleton.cpu().numpy()
        
        normalized_skeletons = []
        for i in range(skeleton.shape[0]):
            single_skeleton = skeleton[i]
            
            # å‚ç…§gcn_skeleton_gif_visualizer.pyçš„å¤„ç†ï¼š
            # skeletonæ˜¯å·²ç»è½¬æ¢ä¸º(x,y,z)æ ¼å¼çš„å¯è§†åŒ–æ•°æ®
            # éœ€è¦è½¬æ¢å›(x,z,y)æ ¼å¼ç”¨äºæ¨¡å‹æ¨ç†
            single_skeleton_xzy = single_skeleton[:, [0, 2, 1]]  # [x,y,z] -> [x,z,y]
            
            # å…ˆå¯¹é½éª¨æ¶æ–¹å‘ï¼Œå‡å°‘æ—‹è½¬å¯¼è‡´çš„é‡å»ºé”™è¯¯ï¼ˆå‚è€ƒåŸå§‹ä»£ç ï¼‰
            aligned = self._align_skeleton_orientation(single_skeleton_xzy)
            
            # ä½¿ç”¨ä¸è®­ç»ƒæ—¶ä¸€è‡´çš„æ ‡å‡†åŒ–æ–¹æ³•
            normalized = self._normalize_single_skeleton(aligned)
                
            normalized_skeletons.append(normalized)
        
        return np.array(normalized_skeletons)
    
    def _align_skeleton_orientation(self, skeleton):
        """å¯¹é½éª¨æ¶æ–¹å‘ï¼Œå‡å°‘æ—‹è½¬å¯¼è‡´çš„é‡å»ºé”™è¯¯ï¼ˆå‚è€ƒgcn_skeleton_gif_visualizer.pyï¼‰"""
        # è®¡ç®—ä¸»è¦èº«ä½“è½´å‘ï¼ˆä»éª¨ç›†åˆ°å¤´éƒ¨ï¼‰
        # NTU RGB+Då…³èŠ‚ç‚¹ç´¢å¼•ï¼š0=éª¨ç›†ä¸­å¿ƒ, 3=å¤´é¡¶
        if len(skeleton) >= 4:
            pelvis = skeleton[0]  # éª¨ç›†ä¸­å¿ƒ
            head = skeleton[3]   # å¤´é¡¶
            
            # è®¡ç®—èº«ä½“ä¸»è½´
            body_axis = head - pelvis
            body_axis_norm = np.linalg.norm(body_axis)
            
            if body_axis_norm > 1e-6:
                # å°†èº«ä½“ä¸»è½´å¯¹é½åˆ°Yè½´æ­£æ–¹å‘
                target_axis = np.array([0, 1, 0])
                body_axis_normalized = body_axis / body_axis_norm
                
                # è®¡ç®—æ—‹è½¬è§’åº¦
                cos_angle = np.dot(body_axis_normalized, target_axis)
                cos_angle = np.clip(cos_angle, -1.0, 1.0)
                
                # å¦‚æœèº«ä½“è½´å‘ä¸Yè½´ç›¸åï¼ˆå€’ç«‹ï¼‰ï¼Œè¿›è¡Œ180åº¦æ—‹è½¬
                if cos_angle < -0.5:  # è§’åº¦å¤§äº120åº¦ï¼Œè®¤ä¸ºæ˜¯å€’ç«‹
                    # ç»•Xè½´æ—‹è½¬180åº¦
                    rotation_matrix = np.array([
                        [1, 0, 0],
                        [0, -1, 0],
                        [0, 0, -1]
                    ])
                    skeleton = np.dot(skeleton, rotation_matrix.T)
        
        return skeleton
    
    def _normalize_single_skeleton(self, skeleton):
        """æ ‡å‡†åŒ–å•ä¸ªéª¨æ¶"""
        # è®¡ç®—è´¨å¿ƒ
        centroid = np.mean(skeleton, axis=0)
        centered = skeleton - centroid
        
        # ä½¿ç”¨æœ€å¤§è·ç¦»è¿›è¡Œç¼©æ”¾ï¼ˆä¸è®­ç»ƒæ—¶ä¸€è‡´ï¼‰
        distances = np.sqrt(np.sum(centered**2, axis=1))
        max_distance = np.max(distances)
        
        if max_distance > 0:
            normalized = centered / max_distance
        else:
            normalized = centered
            
        return normalized
    
    def process_complete_pipeline(self, radar_feature_map):
        """å®Œæ•´çš„å¤„ç†æµç¨‹ï¼šé›·è¾¾ â†’ éª¨æ¶æå– â†’ GCNé‡æ„"""
        print("ğŸ”„ æ‰§è¡Œå®Œæ•´å¤„ç†æµç¨‹...")
        
        # æ­¥éª¤1ï¼šä»é›·è¾¾æ•°æ®æå–éª¨æ¶
        print("  1ï¸âƒ£ ä»é›·è¾¾ç‰¹å¾å›¾æå–éª¨æ¶...")
        extracted_skeleton = self.extract_skeleton_from_radar(radar_feature_map)
        print(f"     âœ… æå–éª¨æ¶å½¢çŠ¶: {extracted_skeleton.shape}")
        
        # æ­¥éª¤2ï¼šä½¿ç”¨GCNé‡æ„éª¨æ¶
        print("  2ï¸âƒ£ ä½¿ç”¨GCNç æœ¬é‡æ„éª¨æ¶...")
        reconstruction_result = self.reconstruct_skeleton_with_gcn(extracted_skeleton)
        print(f"     âœ… é‡æ„å®Œæˆï¼ŒVQæŸå¤±: {reconstruction_result['vq_loss']:.6f}")
        
        # æ­¥éª¤3ï¼šåˆ†æTokenåºåˆ—
        print("  3ï¸âƒ£ åˆ†æTokenåºåˆ—...")
        token_sequence = reconstruction_result['token_sequence']
        print(f"     Tokenåºåˆ—å½¢çŠ¶: {token_sequence.shape}")
        
        if len(reconstruction_result.get('group_results', {})) > 0:
            for group_name, result in reconstruction_result['group_results'].items():
                if isinstance(result, dict) and 'indices' in result:
                    indices = result['indices']
                    if hasattr(indices, 'cpu'):
                        indices = indices.cpu().numpy()
                    print(f"     {group_name}: Token ID = {indices}")
        
        return {
            'radar_input': radar_feature_map,
            'extracted_skeleton': extracted_skeleton,
            'reconstruction_result': reconstruction_result
        }
    
    def visualize_results(self, pipeline_results_list, save_path):
        """å¯è§†åŒ–å¤šä¸ªæ ·æœ¬çš„æµç¨‹ç»“æœ"""
        print(f"ğŸ¨ ç”Ÿæˆå¤šæ ·æœ¬å¯è§†åŒ–ç»“æœ...")
        
        num_samples = len(pipeline_results_list)
        # åˆ›å»º2x2ç½‘æ ¼ï¼Œæ¯ä¸ªæ ·æœ¬æ˜¾ç¤º4ä¸ªå­å›¾ï¼š3ä¸ªéª¨æ¶+1ä¸ªè¯¯å·®
        fig = plt.figure(figsize=(20, 16))
        
        for sample_idx, pipeline_result in enumerate(pipeline_results_list):
            extracted_skeleton = pipeline_result['extracted_skeleton'][0]  # å–ç¬¬ä¸€ä¸ªæ ·æœ¬
            reconstruction_result = pipeline_result['reconstruction_result']
            normalized_skeleton = reconstruction_result['normalized'][0]  # MARSæ ‡ç­¾éª¨æ¶ï¼ˆå½’ä¸€åŒ–åï¼‰
            reconstructed_skeleton = reconstruction_result['reconstructed'][0]
            
            # ä¸ºæ¯ä¸ªæ ·æœ¬åˆ›å»º4ä¸ªå­å›¾
            base_idx = sample_idx * 4
            
            # 1. MARSæ ‡ç­¾éª¨æ¶ï¼ˆå½’ä¸€åŒ–ï¼‰
            ax1 = fig.add_subplot(num_samples, 4, base_idx + 1, projection='3d')
            self._plot_skeleton_3d(ax1, normalized_skeleton, f'Sample {sample_idx+1}: MARS Label Skeleton', 'blue')
            
            # 2. æå–éª¨æ¶ï¼ˆåŸå§‹ï¼‰
            ax2 = fig.add_subplot(num_samples, 4, base_idx + 2, projection='3d')
            self._plot_skeleton_3d(ax2, extracted_skeleton, f'Sample {sample_idx+1}: Extracted Skeleton', 'green')
            
            # 3. é‡æ„éª¨æ¶
            ax3 = fig.add_subplot(num_samples, 4, base_idx + 3, projection='3d')
            self._plot_skeleton_3d(ax3, reconstructed_skeleton, f'Sample {sample_idx+1}: Reconstructed Skeleton', 'red')
            
            # 4. å…³èŠ‚é‡å»ºæŸå¤±
            ax4 = fig.add_subplot(num_samples, 4, base_idx + 4)
            errors = np.sqrt(np.sum((normalized_skeleton - reconstructed_skeleton)**2, axis=1))
            bars = ax4.bar(range(len(errors)), errors)
            ax4.set_title(f'Sample {sample_idx+1}: Joint Reconstruction Errors', fontsize=10, fontweight='bold')
            ax4.set_xlabel('Joint Index')
            ax4.set_ylabel('Error (L2)')
            
            # ä¸ºè¯¯å·®é«˜çš„å…³èŠ‚ç‚¹æ ‡è®°é¢œè‰²
            max_error = np.max(errors)
            for i, bar in enumerate(bars):
                if errors[i] > max_error * 0.7:
                    bar.set_color('red')
                elif errors[i] > max_error * 0.4:
                    bar.set_color('orange')
                else:
                    bar.set_color('green')
        
        # è®¡ç®—æ€»ä½“ç»Ÿè®¡ä¿¡æ¯
        all_mse_errors = []
        all_vq_losses = []
        all_max_errors = []
        all_mean_errors = []
        
        for pipeline_result in pipeline_results_list:
            reconstruction_result = pipeline_result['reconstruction_result']
            normalized_skeleton = reconstruction_result['normalized'][0]
            reconstructed_skeleton = reconstruction_result['reconstructed'][0]
            
            mse_error = np.mean((normalized_skeleton - reconstructed_skeleton)**2)
            vq_loss = reconstruction_result['vq_loss']
            errors = np.sqrt(np.sum((normalized_skeleton - reconstructed_skeleton)**2, axis=1))
            
            all_mse_errors.append(mse_error)
            all_vq_losses.append(vq_loss)
            all_max_errors.append(np.max(errors))
            all_mean_errors.append(np.mean(errors))
        
        # æ·»åŠ æ•´ä½“æ ‡é¢˜
        avg_mse = np.mean(all_mse_errors)
        avg_vq = np.mean(all_vq_losses)
        plt.suptitle(f'Multi-Sample Skeleton Analysis ({num_samples} samples)\\n'
                    f'Avg MSE: {avg_mse:.6f} | Avg VQ Loss: {avg_vq:.6f}', 
                    fontsize=16, fontweight='bold')
        
        plt.tight_layout(rect=[0, 0, 1, 0.95])
        
        # ä¿å­˜å›¾åƒ
        plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white')
        plt.close()
        
        print(f"âœ… å¤šæ ·æœ¬å¯è§†åŒ–ç»“æœå·²ä¿å­˜: {save_path}")
        
        return {
            'mse_error': float(np.mean(all_mse_errors)),
            'vq_loss': float(np.mean(all_vq_losses)),
            'max_joint_error': float(np.mean(all_max_errors)),
            'mean_joint_error': float(np.mean(all_mean_errors)),
            'sample_details': [
                {
                    'mse_error': float(all_mse_errors[i]),
                    'vq_loss': float(all_vq_losses[i]),
                    'max_joint_error': float(all_max_errors[i]),
                    'mean_joint_error': float(all_mean_errors[i])
                } for i in range(num_samples)
            ]
        }
    
    def _plot_skeleton_3d(self, ax, skeleton, title, color):
        """ç»˜åˆ¶3Déª¨æ¶ï¼Œç‰¹åˆ«å¤„ç†MARSæ˜ å°„çš„6ä¸ªé¢å¤–å…³èŠ‚ç‚¹"""
        # ç¡®ä¿skeletonæ˜¯numpyæ•°ç»„
        if isinstance(skeleton, torch.Tensor):
            skeleton = skeleton.cpu().numpy()
        
        # ç»˜åˆ¶éª¨éª¼è¿æ¥
        for edge in self.skeleton_edges:
            if edge[0] < len(skeleton) and edge[1] < len(skeleton):
                start = skeleton[edge[0]]
                end = skeleton[edge[1]]
                if not (np.all(start == 0) or np.all(end == 0)):
                    ax.plot3D([start[0], end[0]], [start[1], end[1]], [start[2], end[2]],
                             color=color, alpha=0.8, linewidth=2.0)
        
        # ç»˜åˆ¶åŸå§‹19ä¸ªå…³èŠ‚ç‚¹ï¼ˆMARSç›´æ¥æ˜ å°„çš„ï¼‰
        original_joints = [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20]
        for i in original_joints:
            if i < len(skeleton):
                joint = skeleton[i]
                if not np.all(joint == 0):
                    ax.scatter(joint[0], joint[1], joint[2],
                              c=color, s=25, alpha=0.9, edgecolors='white', linewidth=0.5)
        
        # çªå‡ºæ˜¾ç¤ºæ˜ å°„ç”Ÿæˆçš„6ä¸ªé¢å¤–å…³èŠ‚ç‚¹ï¼ˆæ‰‹éƒ¨å…³èŠ‚ï¼‰
        interpolated_joints = [7, 11, 21, 22, 23, 24]  # å¯¹åº”lefthand, righthand, lefthandtip, leftthumb, righthandtip, rightthumb
        for i in interpolated_joints:
            if i < len(skeleton):
                joint = skeleton[i]
                if not np.all(joint == 0):
                    # ä½¿ç”¨ä¸åŒçš„é¢œè‰²å’Œæ ‡è®°çªå‡ºæ˜¾ç¤ºæ˜ å°„çš„å…³èŠ‚ç‚¹
                    marker_color = 'orange' if 'blue' in color.lower() else 'lightcoral'
                    ax.scatter(joint[0], joint[1], joint[2],
                              c=marker_color, s=35, alpha=1.0, 
                              edgecolors='black', linewidth=1.0, marker='^')  # ä¸‰è§’å½¢æ ‡è®°
        
        ax.set_title(title, fontsize=12, fontweight='bold')
        ax.set_xlabel('X')
        ax.set_ylabel('Y')
        ax.set_zlabel('Z')
        
        # è®¾ç½®ç­‰æ¯”ä¾‹åæ ‡èŒƒå›´
        valid_joints = skeleton[~np.all(skeleton == 0, axis=1)]
        if len(valid_joints) > 0:
            # è®¡ç®—éª¨æ¶çš„å®é™…èŒƒå›´
            min_coords = np.min(valid_joints, axis=0)
            max_coords = np.max(valid_joints, axis=0)
            center = np.mean(valid_joints, axis=0)
            
            # è®¡ç®—æœ€å¤§èŒƒå›´ä»¥ç¡®ä¿ç­‰æ¯”ä¾‹
            ranges = max_coords - min_coords
            max_range = max(np.max(ranges) / 2, 0.3)  # æœ€å°èŒƒå›´0.3
            
            # è®¾ç½®ç­‰æ¯”ä¾‹åæ ‡è½´
            ax.set_xlim([center[0] - max_range, center[0] + max_range])
            ax.set_ylim([center[1] - max_range, center[1] + max_range])
            ax.set_zlim([center[2] - max_range, center[2] + max_range])
            
            # å¼ºåˆ¶ç­‰æ¯”ä¾‹ - å‚ç…§ä¸¤ä¸ªå‚è€ƒæ–‡ä»¶çš„è®¾ç½®æ–¹å¼
            ax.set_box_aspect([1,1,1])
        
        # å‚è€ƒgcn_skeleton_gif_visualizer.pyçš„è§†è§’è®¾ç½®
        ax.view_init(elev=15, azim=45)
    
    def generate_individual_sample_visualizations(self, pipeline_results, output_dir):
        """ä¸ºæ¯ä¸ªæ ·æœ¬ç”Ÿæˆå•ç‹¬çš„å¯è§†åŒ–å›¾ç‰‡"""
        print(f"ğŸ–¼ï¸ ç”Ÿæˆå•ç‹¬æ ·æœ¬å¯è§†åŒ–...")
        
        individual_metrics = []
        
        for i, result in enumerate(pipeline_results):
            sample_idx = i + 1
            
            # æå–æ•°æ® - ä¿®æ­£é”®å
            radar_input = result['radar_input']
            extracted_skeleton = result['extracted_skeleton'][0].cpu().numpy() if isinstance(result['extracted_skeleton'], torch.Tensor) else result['extracted_skeleton'][0]
            reconstructed_skeleton = result['reconstruction_result']['reconstructed'][0]
            
            # è®¡ç®—è¯¯å·®
            mse_error = np.mean((extracted_skeleton - reconstructed_skeleton) ** 2)
            joint_errors = np.sqrt(np.sum((extracted_skeleton - reconstructed_skeleton) ** 2, axis=1))
            max_joint_error = np.max(joint_errors)
            mean_joint_error = np.mean(joint_errors)
            
            # åˆ›å»ºå•ç‹¬çš„å›¾å½¢ - 1è¡Œ3åˆ—å¸ƒå±€
            fig = plt.figure(figsize=(18, 6))
            
            # è®¾ç½®ä¸­æ–‡å­—ä½“
            plt.rcParams['font.sans-serif'] = ['DejaVu Sans']
            plt.rcParams['axes.unicode_minus'] = False
            
            # é›·è¾¾è¾“å…¥å¯è§†åŒ– (æ˜¾ç¤ºé›·è¾¾ç‰¹å¾å›¾ä¿¡æ¯)
            ax1 = fig.add_subplot(131, projection='3d')
            # ç”±äºåŸå§‹éª¨æ¶æ•°æ®ä¸ç›´æ¥å¯ç”¨ï¼Œæ˜¾ç¤ºé›·è¾¾è¾“å…¥çš„ç»´åº¦ä¿¡æ¯
            ax1.text(0.5, 0.5, 0.5, f'é›·è¾¾ç‰¹å¾å›¾\n{radar_input.shape}', ha='center', va='center', fontsize=14,
                    bbox=dict(boxstyle="round,pad=0.3", facecolor="lightblue", alpha=0.8))
            ax1.set_title(f'æ ·æœ¬ {sample_idx}: é›·è¾¾è¾“å…¥', fontsize=12, fontweight='bold')
            ax1.set_xlim([0, 1])
            ax1.set_ylim([0, 1])
            ax1.set_zlim([0, 1])
            
            # æå–çš„éª¨æ¶
            ax2 = fig.add_subplot(132, projection='3d')
            self._plot_skeleton_3d(ax2, extracted_skeleton, f'æ ·æœ¬ {sample_idx}: æå–éª¨æ¶', 'green')
            
            # é‡æ„çš„éª¨æ¶ 
            ax3 = fig.add_subplot(133, projection='3d')
            self._plot_skeleton_3d(ax3, reconstructed_skeleton, f'æ ·æœ¬ {sample_idx}: GCNé‡æ„', 'red')
            
            # æ·»åŠ è¯¯å·®ä¿¡æ¯
            fig.suptitle(f'æ ·æœ¬ {sample_idx} - éª¨æ¶æå–ä¸é‡æ„å¯¹æ¯”\n'
                        f'MSEè¯¯å·®: {mse_error:.4f} | æœ€å¤§å…³èŠ‚è¯¯å·®: {max_joint_error:.4f} | å¹³å‡å…³èŠ‚è¯¯å·®: {mean_joint_error:.4f}',
                        fontsize=16, fontweight='bold', y=0.95)
            
            # æ·»åŠ Tokenä¿¡æ¯
            token_sequence = result['reconstruction_result']['token_sequence'][0]
            token_text = f"Tokenåºåˆ—: {list(token_sequence)}"
            fig.text(0.02, 0.02, token_text, fontsize=10, 
                    bbox=dict(boxstyle="round,pad=0.3", facecolor="lightblue", alpha=0.8))
            
            plt.tight_layout()
            
            # ä¿å­˜å›¾ç‰‡
            save_path = os.path.join(output_dir, f'extraction_reconstruction_sample_{sample_idx:02d}.png')
            plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white', edgecolor='none')
            plt.close()
            
            print(f"âœ… å·²ä¿å­˜æ ·æœ¬ {sample_idx:02d}: {os.path.basename(save_path)}")
            
            individual_metrics.append({
                'sample_id': sample_idx,
                'mse_error': mse_error,
                'max_joint_error': max_joint_error,
                'mean_joint_error': mean_joint_error,
                'token_sequence': list(token_sequence),
                'file_path': save_path
            })
        
        return individual_metrics
    
    def generate_sequence_gif_animations(self, radar_data_path, output_dir, num_sequences=5, frames_per_sequence=8, fps=3):
        """ç”Ÿæˆç›¸é‚»å‡ å¸§çš„GIFåŠ¨ç”»å±•ç¤ºé‡æ„è¿‡ç¨‹
        
        Args:
            radar_data_path: é›·è¾¾æ•°æ®è·¯å¾„
            output_dir: GIFä¿å­˜ç›®å½•
            num_sequences: ç”Ÿæˆåºåˆ—æ•°é‡
            frames_per_sequence: æ¯ä¸ªåºåˆ—çš„å¸§æ•°
            fps: GIFå¸§ç‡
        """
        print(f"ğŸ¬ ç”Ÿæˆéª¨æ¶é‡æ„GIFåŠ¨ç”»...")
        
        # åˆ›å»ºGIFè¾“å‡ºç›®å½•
        gif_output_dir = os.path.join(output_dir, "../skeleton_extraction_gif_reconstruction")
        os.makedirs(gif_output_dir, exist_ok=True)
        
        # åŠ è½½å®Œæ•´çš„é›·è¾¾æ•°æ®
        if not os.path.exists(radar_data_path):
            print(f"âŒ é›·è¾¾æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {radar_data_path}")
            return []
        
        full_data = np.load(radar_data_path)
        print(f"âœ… åŠ è½½å®Œæ•´é›·è¾¾æ•°æ®: {full_data.shape}")
        
        gif_info_list = []
        
        # ç”Ÿæˆå¤šä¸ªåºåˆ—çš„GIF
        for seq_idx in range(num_sequences):
            # ä¸ºæ¯ä¸ªåºåˆ—é€‰æ‹©ä¸åŒçš„èµ·å§‹ä½ç½®
            start_idx = seq_idx * (len(full_data) // (num_sequences + 1))
            end_idx = min(start_idx + frames_per_sequence, len(full_data))
            
            if end_idx - start_idx < frames_per_sequence:
                # å¦‚æœæ•°æ®ä¸å¤Ÿï¼Œä»æœ«å°¾å‘å‰å–
                end_idx = len(full_data) - 1
                start_idx = max(0, end_idx - frames_per_sequence + 1)
            
            print(f"ğŸ“¹ ç”Ÿæˆåºåˆ— {seq_idx+1}/{num_sequences}: å¸§ {start_idx}-{end_idx-1}")
            
            # æå–åºåˆ—æ•°æ®
            sequence_data = full_data[start_idx:end_idx]
            
            # å¤„ç†åºåˆ—ä¸­çš„æ¯ä¸€å¸§
            frame_results = []
            for frame_idx, radar_frame in enumerate(sequence_data):
                # å¤„ç†å•å¸§
                frame_result = self.process_complete_pipeline(radar_frame.reshape(1, 8, 8, 5))
                frame_results.append({
                    'frame_idx': frame_idx,
                    'extracted': frame_result['extracted_skeleton'][0].cpu().numpy(),
                    'reconstructed': frame_result['reconstruction_result']['reconstructed'][0],
                    'vq_loss': frame_result['reconstruction_result']['vq_loss'],
                    'tokens': frame_result['reconstruction_result']['token_sequence'][0]
                })
            
            # ç”ŸæˆGIF
            gif_path = os.path.join(gif_output_dir, f'skeleton_reconstruction_sequence_{seq_idx+1:02d}.gif')
            gif_info = self._create_skeleton_sequence_gif(frame_results, gif_path, fps)
            gif_info['sequence_id'] = seq_idx + 1
            gif_info['start_frame'] = start_idx
            gif_info['end_frame'] = end_idx - 1
            gif_info_list.append(gif_info)
            
        return gif_info_list
    
    def _create_skeleton_sequence_gif(self, frame_results, gif_path, fps=3):
        """åˆ›å»ºå•ä¸ªåºåˆ—çš„éª¨æ¶é‡æ„GIFåŠ¨ç”»"""
        
        num_frames = len(frame_results)
        if num_frames == 0:
            return {'success': False, 'path': gif_path}
        
        # åˆ›å»ºå›¾å½¢å¸ƒå±€: 1è¡Œ2åˆ—
        fig = plt.figure(figsize=(16, 8))
        
        # è®¾ç½®ä¸­æ–‡å­—ä½“
        plt.rcParams['font.sans-serif'] = ['DejaVu Sans']
        plt.rcParams['axes.unicode_minus'] = False
        
        def animate(frame_idx):
            """åŠ¨ç”»æ›´æ–°å‡½æ•°"""
            fig.clear()
            
            # è·å–å½“å‰å¸§æ•°æ®
            current_frame = frame_results[frame_idx]
            extracted = current_frame['extracted']
            reconstructed = current_frame['reconstructed']
            vq_loss = current_frame['vq_loss']
            tokens = current_frame['tokens']
            
            # è®¡ç®—é‡æ„è¯¯å·®
            mse_error = np.mean((extracted - reconstructed) ** 2)
            
            # åˆ›å»ºå­å›¾
            ax1 = fig.add_subplot(121, projection='3d')
            ax2 = fig.add_subplot(122, projection='3d')
            
            # ç»˜åˆ¶æå–çš„éª¨æ¶
            self._plot_skeleton_3d(ax1, extracted, 
                                 f'Frame {frame_idx+1}/{num_frames}: Extracted Skeleton', 'green')
            
            # ç»˜åˆ¶é‡æ„çš„éª¨æ¶
            self._plot_skeleton_3d(ax2, reconstructed,
                                 f'Frame {frame_idx+1}/{num_frames}: Reconstructed Skeleton\nVQ Loss: {vq_loss:.4f}', 'red')
            
            # è®¾ç½®æ€»æ ‡é¢˜
            fig.suptitle(f'Skeleton Reconstruction Animation\n'
                        f'Frame {frame_idx+1}/{num_frames} | MSE: {mse_error:.4f} | Tokens: {list(tokens)[:3]}...',
                        fontsize=14, fontweight='bold', y=0.95)
            
            # è°ƒæ•´å¸ƒå±€
            plt.tight_layout()
        
        # åˆ›å»ºåŠ¨ç”»
        try:
            anim = FuncAnimation(fig, animate, frames=num_frames, interval=1000//fps, blit=False, repeat=True)
            
            # ä¿å­˜GIF
            writer = PillowWriter(fps=fps)
            anim.save(gif_path, writer=writer, dpi=150)
            plt.close(fig)
            
            print(f"âœ… GIFä¿å­˜æˆåŠŸ: {os.path.basename(gif_path)}")
            
            # è®¡ç®—åºåˆ—ç»Ÿè®¡
            mse_errors = [np.mean((fr['extracted'] - fr['reconstructed']) ** 2) for fr in frame_results]
            vq_losses = [fr['vq_loss'] for fr in frame_results]
            
            return {
                'success': True,
                'path': gif_path,
                'num_frames': num_frames,
                'avg_mse': np.mean(mse_errors),
                'avg_vq_loss': np.mean(vq_losses),
                'frame_range': (0, num_frames-1)
            }
            
        except Exception as e:
            print(f"âŒ GIFç”Ÿæˆå¤±è´¥: {e}")
            plt.close(fig)
            return {
                'success': False,
                'path': gif_path,
                'error': str(e)
            }

def load_test_radar_data(data_path, num_samples=12):
    """åŠ è½½æµ‹è¯•é›·è¾¾æ•°æ® - å¢åŠ æ ·æœ¬æ•°é‡ä»¥å±•ç¤ºæ›´å¤šåŠ¨ä½œ"""
    print(f"ğŸ“ åŠ è½½æµ‹è¯•æ•°æ®: {data_path}")
    
    try:
        # å°è¯•åŠ è½½æµ‹è¯•æ•°æ®
        if os.path.exists(data_path):
            test_data = np.load(data_path)
            print(f"âœ… æˆåŠŸåŠ è½½æ•°æ®ï¼Œå½¢çŠ¶: {test_data.shape}")
            
            # ä¸ºäº†è·å¾—æ›´å¤šæ ·åŒ–çš„åŠ¨ä½œï¼Œä»ä¸åŒä½ç½®é‡‡æ ·
            if len(test_data) > num_samples:
                # å‡åŒ€é‡‡æ ·ä»¥è·å¾—æ›´å¤šæ ·åŒ–çš„åŠ¨ä½œ
                indices = np.linspace(0, len(test_data) - 1, num_samples, dtype=int)
                test_data = test_data[indices]
                print(f"âœ… ä» {len(test_data)} ä¸ªæ ·æœ¬ä¸­å‡åŒ€é‡‡æ · {num_samples} ä¸ªï¼Œç´¢å¼•: {indices}")
            
            return test_data
        else:
            print(f"âŒ æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {data_path}")
            print("ğŸ”„ ç”Ÿæˆæ¨¡æ‹Ÿé›·è¾¾æ•°æ®...")
            
            # ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®
            mock_data = np.random.rand(num_samples, 8, 8, 5).astype(np.float32)
            return mock_data
            
    except Exception as e:
        print(f"âŒ åŠ è½½æ•°æ®å¤±è´¥: {e}")
        print("ğŸ”„ ç”Ÿæˆæ¨¡æ‹Ÿé›·è¾¾æ•°æ®...")
        
        # ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®
        mock_data = np.random.rand(num_samples, 8, 8, 5).astype(np.float32)
        return mock_data

def main():
    """ä¸»å‡½æ•°"""
    print("=" * 80)
    print("ğŸš€ éª¨æ¶æå– + GCNé‡æ„å®Œæ•´æµç¨‹")
    print("=" * 80)
    
    # é…ç½®æ–‡ä»¶è·¯å¾„
    extractor_model_path = "mars_transformer_best.pth"
    gcn_model_path = "experiments/gcn_skeleton_memory_optimized/NTU_models/default/ckpt-best.pth"
    gcn_config_path = "cfgs/NTU_models/gcn_skeleton_memory_optimized.yaml"
    
    # æ£€æŸ¥æ–‡ä»¶å­˜åœ¨æ€§
    if not os.path.exists(extractor_model_path):
        print(f"âŒ éª¨æ¶æå–å™¨æƒé‡ä¸å­˜åœ¨: {extractor_model_path}")
        return
        
    if not os.path.exists(gcn_model_path):
        print(f"âŒ GCNé‡æ„å™¨æƒé‡ä¸å­˜åœ¨: {gcn_model_path}")
        return
        
    if not os.path.exists(gcn_config_path):
        print(f"âŒ GCNé…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {gcn_config_path}")
        return
    
    print("âœ… æ‰€æœ‰å¿…éœ€æ–‡ä»¶å­˜åœ¨")
    
    try:
        # åˆ›å»ºæµæ°´çº¿
        print("\\nğŸ—ï¸ åˆå§‹åŒ–å¤„ç†æµæ°´çº¿...")
        pipeline = SkeletonExtractionReconstructionPipeline(
            extractor_model_path, gcn_model_path, gcn_config_path
        )
        
        # åŠ è½½æµ‹è¯•æ•°æ®
        print("\\nğŸ“Š åŠ è½½æµ‹è¯•æ•°æ®...")
        radar_data_path = "/home/uo/myProject/HumanPoint-BERT/data/MARS/featuremap_test.npy"
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        output_dir = "visualizations/skeleton_extraction_reconstruction"
        os.makedirs(output_dir, exist_ok=True)
        
        # å¢åŠ æ ·æœ¬æ•°é‡ä»¥å±•ç¤ºæ›´å¤šåŠ¨ä½œ
        num_samples = 12  # å¢åŠ åˆ°12ä¸ªæ ·æœ¬
        test_radar_data = load_test_radar_data(radar_data_path, num_samples=num_samples)
        
        # å¤„ç†æ¯ä¸ªæµ‹è¯•æ ·æœ¬
        print(f"\\nğŸ¯ å¤„ç† {len(test_radar_data)} ä¸ªæµ‹è¯•æ ·æœ¬...")
        
        all_pipeline_results = []
        all_results = []
        
        for i, radar_sample in enumerate(test_radar_data):
            print(f"\\n--- å¤„ç†æ ·æœ¬ {i+1}/{len(test_radar_data)} ---")
            
            # æ‰§è¡Œå®Œæ•´æµç¨‹
            pipeline_result = pipeline.process_complete_pipeline(radar_sample)
            all_pipeline_results.append(pipeline_result)
        
        # ç”Ÿæˆä¸ªåˆ«æ ·æœ¬å¯è§†åŒ–
        print(f"\\nğŸ–¼ï¸ ç”Ÿæˆæ¯ä¸ªæ ·æœ¬çš„å•ç‹¬å¯è§†åŒ–...")
        individual_metrics = pipeline.generate_individual_sample_visualizations(all_pipeline_results, output_dir)
        
        # ç”Ÿæˆå¤šæ ·æœ¬ç»¼åˆå¯è§†åŒ–
        print(f"\\nğŸ¨ ç”Ÿæˆå¤šæ ·æœ¬ç»¼åˆå¯è§†åŒ–...")
        multi_sample_save_path = os.path.join(output_dir, f'multi_sample_skeleton_analysis.png')
        multi_metrics = pipeline.visualize_results(all_pipeline_results, multi_sample_save_path)
        
        # ç”ŸæˆGIFåŠ¨ç”»åºåˆ—
        print(f"\\nğŸ¬ ç”Ÿæˆéª¨æ¶é‡æ„GIFåŠ¨ç”»åºåˆ—...")
        gif_info_list = pipeline.generate_sequence_gif_animations(
            radar_data_path=radar_data_path,
            output_dir=output_dir,
            num_sequences=6,  # ç”Ÿæˆ6ä¸ªGIFåºåˆ—
            frames_per_sequence=6,  # æ¯ä¸ªåºåˆ—6å¸§
            fps=2  # 2å¸§æ¯ç§’ï¼Œè¾ƒæ…¢ä»¥ä¾¿è§‚å¯Ÿç»†èŠ‚
        )
            
        # ä»å¤šæ ·æœ¬æŒ‡æ ‡ä¸­æå–æ¯ä¸ªæ ·æœ¬çš„ç»“æœ
        for i, sample_detail in enumerate(multi_metrics['sample_details']):
            result_summary = {
                'sample_id': int(i + 1),
                'mse_error': float(sample_detail['mse_error']),
                'vq_loss': float(sample_detail['vq_loss']),
                'max_joint_error': float(sample_detail['max_joint_error']),
                'mean_joint_error': float(sample_detail['mean_joint_error']),
                'token_sequence': [int(x) for x in all_pipeline_results[i]['reconstruction_result']['token_sequence'][0].tolist()]
            }
            all_results.append(result_summary)
            
            print(f"  ğŸ“Š æ ·æœ¬ {i+1} æŒ‡æ ‡:")
            print(f"     MSEè¯¯å·®: {sample_detail['mse_error']:.6f}")
            print(f"     VQæŸå¤±: {sample_detail['vq_loss']:.6f}")
            print(f"     æœ€å¤§å…³èŠ‚è¯¯å·®: {sample_detail['max_joint_error']:.6f}")
            print(f"     å¹³å‡å…³èŠ‚è¯¯å·®: {sample_detail['mean_joint_error']:.6f}")
        
        # ä¿å­˜æ‰€æœ‰ç»“æœ
        import json
        results_path = os.path.join(output_dir, 'pipeline_results.json')
        with open(results_path, 'w') as f:
            json.dump(all_results, f, indent=2)
        
        # è®¡ç®—æ€»ä½“ç»Ÿè®¡
        print("\\n" + "=" * 80)
        print("ğŸ“ˆ æ€»ä½“ç»Ÿè®¡ç»“æœ:")
        print("=" * 80)
        
        mse_errors = [r['mse_error'] for r in all_results]
        vq_losses = [r['vq_loss'] for r in all_results]
        
        print(f"å¹³å‡MSEè¯¯å·®: {np.mean(mse_errors):.6f} Â± {np.std(mse_errors):.6f}")
        print(f"å¹³å‡VQæŸå¤±: {np.mean(vq_losses):.6f} Â± {np.std(vq_losses):.6f}")
        print(f"æœ€ä½³MSEè¯¯å·®: {np.min(mse_errors):.6f}")
        print(f"æœ€å·®MSEè¯¯å·®: {np.max(mse_errors):.6f}")
        
        print(f"\\nğŸ“ è¾“å‡ºæ–‡ä»¶:")
        print(f"  ä¸ªåˆ«æ ·æœ¬å¯è§†åŒ–: {len(individual_metrics)} å¼ PNGå›¾ç‰‡")
        print(f"  å¤šæ ·æœ¬ç»¼åˆå›¾: {os.path.basename(multi_sample_save_path)}")  
        print(f"  GIFåŠ¨ç”»åºåˆ—: {len(gif_info_list)} ä¸ªGIFæ–‡ä»¶")
        print(f"  ç»Ÿè®¡ç»“æœ: {os.path.basename(results_path)}")
        print(f"  PNGè¾“å‡ºç›®å½•: {output_dir}/")
        print(f"  GIFè¾“å‡ºç›®å½•: visualizations/skeleton_extraction_gif_reconstruction/")
        
        # æ˜¾ç¤ºç”Ÿæˆçš„å›¾ç‰‡åˆ—è¡¨
        print(f"\\nğŸ–¼ï¸ ç”Ÿæˆçš„å¯è§†åŒ–å›¾ç‰‡:")
        for i, metric in enumerate(individual_metrics):
            print(f"  æ ·æœ¬ {i+1:02d}: extraction_reconstruction_sample_{i+1:02d}.png (MSE: {metric['mse_error']:.4f})")
        
        # æ˜¾ç¤ºç”Ÿæˆçš„GIFåˆ—è¡¨
        print(f"\\nğŸ¬ ç”Ÿæˆçš„GIFåŠ¨ç”»:")
        for gif_info in gif_info_list:
            if gif_info['success']:
                print(f"  åºåˆ— {gif_info['sequence_id']:02d}: {os.path.basename(gif_info['path'])} "
                      f"(å¸§ {gif_info['start_frame']}-{gif_info['end_frame']}, "
                      f"å¹³å‡MSE: {gif_info['avg_mse']:.4f})")
            else:
                print(f"  åºåˆ— {gif_info['sequence_id']:02d}: ç”Ÿæˆå¤±è´¥ - {gif_info.get('error', 'æœªçŸ¥é”™è¯¯')}")
        
        print("\\nğŸ‰ éª¨æ¶æå–+GCNé‡æ„æµç¨‹å®Œæˆï¼")
        
    except Exception as e:
        print(f"\\nâŒ æµç¨‹æ‰§è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()