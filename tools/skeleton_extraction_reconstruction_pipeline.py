#!/usr/bin/env python3
"""
éª¨æ¶æå– + GCNé‡æ„ + æ–‡æœ¬æ˜ å°„å®Œæ•´æµç¨‹
ç»“åˆskeleton_extractor.pyçš„é›·è¾¾éª¨æ¶æå–å’ŒGCNSkeletonTokenizer.pyçš„éª¨æ¶é‡æ„
å®ç°é›·è¾¾ä¿¡å· â†’ éª¨æ¶æå– â†’ ç æœ¬ç¼–ç  â†’ é‡æ„å¯è§†åŒ– â†’ æ–‡æœ¬æè¿°çš„å®Œæ•´ç®¡çº¿
"""

import os
import sys
import torch
import numpy as np
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
from pathlib import Path
import cv2
from PIL import Image
import io
import gc
import json
from matplotlib.animation import FuncAnimation, PillowWriter

# å¯¼å…¥æ–‡æœ¬æ˜ å°„æ¨¡å—
try:
    from tools.codebook_text_mapper import CodebookTextMapper
    TEXT_MAPPING_AVAILABLE = True
except ImportError:
    TEXT_MAPPING_AVAILABLE = False
    print("âš ï¸ æ–‡æœ¬æ˜ å°„æ¨¡å—ä¸å¯ç”¨")

# è®¾ç½®matplotlib
import matplotlib
matplotlib.use('Agg')

# æ·»åŠ modelsè·¯å¾„ä»¥å¯¼å…¥å…³èŠ‚ç‚¹æ˜ å°„å™¨
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))
from models.skeleton_joint_mapper import SkeletonJointMapper, EnhancedSkeletonMapper

# é…ç½®ä¸­æ–‡å­—ä½“æ”¯æŒ - è§£å†³ä¸­æ–‡æ˜¾ç¤ºé—®é¢˜
import matplotlib.font_manager as fm

# å°è¯•è®¾ç½®æ”¯æŒä¸­æ–‡çš„å­—ä½“
chinese_fonts = ['SimHei', 'Microsoft YaHei', 'WenQuanYi Micro Hei', 'DejaVu Sans']
font_found = False
for font_name in chinese_fonts:
    try:
        if font_name in [f.name for f in fm.fontManager.ttflist]:
            plt.rcParams['font.sans-serif'] = [font_name]
            font_found = True
            break
    except:
        continue

if not font_found:
    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ä¸­æ–‡å­—ä½“ï¼Œä½¿ç”¨é»˜è®¤å­—ä½“ä½†é¿å…ä¸­æ–‡æ˜¾ç¤º
    plt.rcParams['font.sans-serif'] = ['DejaVu Sans']
    print("âš ï¸ æœªæ‰¾åˆ°ä¸­æ–‡å­—ä½“ï¼Œå°†ä½¿ç”¨è‹±æ–‡æ˜¾ç¤º")

plt.rcParams['axes.unicode_minus'] = False
plt.rcParams['font.size'] = 10

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.append(str(project_root))

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
try:
    from models.skeleton_extractor import MARSTransformerModel
    from models.GCNSkeletonTokenizer import GCNSkeletonTokenizer
    from utils.config import cfg_from_yaml_file
except ImportError as e:
    print(f"Import error: {e}")
    sys.exit(1)

class SkeletonExtractionReconstructionPipeline:
    """éª¨æ¶æå–å’Œé‡æ„å®Œæ•´æµç¨‹ - æ”¯æŒå¤šå°ºåº¦ç‰¹å¾èåˆ"""
    
    def __init__(self, extractor_model_path, gcn_model_path, gcn_config_path, use_enhanced_mapping=True):
        print("=" * 80)
        print("åˆå§‹åŒ–éª¨æ¶æå–å’Œé‡æ„æµç¨‹")
        print("=" * 80)
        
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        print(f"ğŸ–¥ï¸  è®¾å¤‡: {self.device}")
        
        if torch.cuda.is_available():
            print(f"   GPU: {torch.cuda.get_device_name(0)}")
            print(f"   æ˜¾å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
        
        print("\n" + "-" * 80)
        print("æ­¥éª¤ 1/3: åˆå§‹åŒ–å…³èŠ‚ç‚¹æ˜ å°„å™¨")
        print("-" * 80)
        
        # åˆå§‹åŒ–å…³èŠ‚ç‚¹æ˜ å°„å™¨ (MARS 19å…³èŠ‚ -> NTU 25å…³èŠ‚)
        if use_enhanced_mapping:
            self.joint_mapper = EnhancedSkeletonMapper().to(self.device)
            print("ğŸ¯ ä½¿ç”¨å¢å¼ºå…³èŠ‚ç‚¹æ˜ å°„å™¨ (MARS 19å…³èŠ‚ -> NTU 25å…³èŠ‚)")
        else:
            self.joint_mapper = SkeletonJointMapper().to(self.device)
            print("ğŸ¯ ä½¿ç”¨åŸºç¡€å…³èŠ‚ç‚¹æ˜ å°„å™¨ (MARS 19å…³èŠ‚ -> NTU 25å…³èŠ‚)")
        
        print("\n" + "-" * 80)
        print("æ­¥éª¤ 2/3: åŠ è½½éª¨æ¶æå–å™¨")
        print("-" * 80)
        
        # åŠ è½½éª¨æ¶æå–å™¨
        self.skeleton_extractor = self._load_skeleton_extractor(extractor_model_path)
        
        print("\n" + "-" * 80)
        print("æ­¥éª¤ 3/3: åŠ è½½GCNé‡æ„å™¨")
        print("-" * 80)
        
        # åŠ è½½GCNé‡æ„å™¨
        self.gcn_reconstructor = self._load_gcn_reconstructor(gcn_model_path, gcn_config_path)
        
        print("\n" + "-" * 80)
        print("åˆå§‹åŒ–æ–‡æœ¬æ˜ å°„å™¨")
        print("-" * 80)
        
        # åˆå§‹åŒ–æ–‡æœ¬æ˜ å°„å™¨
        if TEXT_MAPPING_AVAILABLE:
            self.text_mapper = CodebookTextMapper()
            print("ğŸ”¤ æ–‡æœ¬æ˜ å°„å™¨åˆå§‹åŒ–å®Œæˆ")
        else:
            self.text_mapper = None
            print("âš ï¸ æ–‡æœ¬æ˜ å°„å™¨ä¸å¯ç”¨")
        
        # NTU RGB+D 25å…³èŠ‚ç‚¹è¿æ¥å…³ç³»
        self.skeleton_edges = [
            (3, 2), (2, 20), (20, 1), (1, 0),  # å¤´éƒ¨å’Œè„ŠæŸ±
            (20, 4), (4, 5), (5, 6), (6, 22), (6, 7), (7, 21),  # å·¦è‡‚
            (20, 8), (8, 9), (9, 10), (10, 24), (10, 11), (11, 23),  # å³è‡‚
            (0, 12), (12, 13), (13, 14), (14, 15),  # å·¦è…¿
            (0, 16), (16, 17), (17, 18), (18, 19)   # å³è…¿
        ]
        
        print("\n" + "=" * 80)
        print("âœ… æµæ°´çº¿åˆå§‹åŒ–å®Œæˆ!")
        print("=" * 80)
    
    def _load_skeleton_extractor(self, model_path):
        """åŠ è½½MARSéª¨æ¶æå–å™¨ - æ”¯æŒå¤šå°ºåº¦ç‰¹å¾èåˆ"""
        print(f"Loading skeleton extractor: {model_path}")
        
        # å°è¯•åŠ è½½æƒé‡ä»¥æ£€æµ‹æ¨¡å‹ç±»å‹
        state_dict = torch.load(model_path, map_location=self.device)
        
        # æ£€æµ‹æ˜¯å¦ä¸ºå¤šå°ºåº¦æ¨¡å‹ï¼ˆé€šè¿‡ç¬¬ä¸€å±‚Linearçš„è¾“å…¥ç»´åº¦åˆ¤æ–­ï¼‰
        # æŸ¥æ‰¾feature_projectionçš„ç¬¬ä¸€å±‚Linearæƒé‡
        first_linear_key = 'regression_head.feature_projection.0.weight'
        
        if first_linear_key in state_dict:
            input_dim = state_dict[first_linear_key].shape[1]  # (out_features, in_features)
            is_multi_scale = (input_dim == 448)
            
            if is_multi_scale:
                print("ğŸ” æ£€æµ‹åˆ°å¤šå°ºåº¦æ¨¡å‹ (448ç»´è¾“å…¥)")
                model = MARSTransformerModel(input_channels=5, output_dim=57, multi_scale=True)
            else:
                print("ğŸ” æ£€æµ‹åˆ°å•å°ºåº¦æ¨¡å‹ (256ç»´è¾“å…¥)")
                model = MARSTransformerModel(input_channels=5, output_dim=57, multi_scale=False)
        else:
            # å¦‚æœæ‰¾ä¸åˆ°å…³é”®å±‚ï¼Œé»˜è®¤å°è¯•å¤šå°ºåº¦ï¼ˆæ–°ç‰ˆæœ¬ï¼‰
            print("âš ï¸ æ— æ³•æ£€æµ‹æ¨¡å‹ç±»å‹ï¼Œé»˜è®¤ä½¿ç”¨å¤šå°ºåº¦æ¨¡å‹")
            model = MARSTransformerModel(input_channels=5, output_dim=57, multi_scale=True)
        
        # åŠ è½½æƒé‡
        try:
            model.load_state_dict(state_dict)
            print("âœ… æƒé‡åŠ è½½æˆåŠŸï¼")
        except RuntimeError as e:
            print(f"âŒ æƒé‡åŠ è½½å¤±è´¥: {e}")
            print("âš ï¸ å¯èƒ½æ˜¯æ¨¡å‹ç‰ˆæœ¬ä¸åŒ¹é…ï¼Œè¯·æ£€æŸ¥æƒé‡æ–‡ä»¶")
            raise
        
        model.to(self.device)
        model.eval()
        
        # è¾“å‡ºæ¨¡å‹ä¿¡æ¯
        total_params = sum(p.numel() for p in model.parameters())
        print(f"ğŸ“Š æ¨¡å‹å‚æ•°: {total_params:,}")
        print(f"ğŸ“Š Backboneè¾“å‡ºç»´åº¦: {model.backbone.output_dim}")
        print("âœ… Skeleton extractor loaded successfully!")
        
        return model
    
    def _load_gcn_reconstructor(self, model_path, config_path):
        """åŠ è½½GCNéª¨æ¶é‡æ„å™¨"""
        print(f"Loading GCN reconstructor: {model_path}")
        
        try:
            # åŠ è½½é…ç½®
            config = cfg_from_yaml_file(config_path)
            print(f"ğŸ“‹ é…ç½®æ–‡ä»¶: {config_path}")
            
            # åˆ›å»ºæ¨¡å‹
            model = GCNSkeletonTokenizer(config.model)
            
            # åŠ è½½æƒé‡
            checkpoint = torch.load(model_path, map_location=self.device)
            
            if 'base_model' in checkpoint:
                state_dict = checkpoint['base_model']
                print("ğŸ” ä½¿ç”¨checkpointä¸­çš„base_model")
            else:
                state_dict = checkpoint
                print("ğŸ” ç›´æ¥åŠ è½½state_dict")
                
            # å¤„ç†åˆ†å¸ƒå¼è®­ç»ƒæƒé‡
            new_state_dict = {}
            for k, v in state_dict.items():
                if k.startswith('module.'):
                    new_state_dict[k[7:]] = v
                else:
                    new_state_dict[k] = v
            
            model.load_state_dict(new_state_dict)
            model.to(self.device)
            model.eval()
            
            # è¾“å‡ºæ¨¡å‹ä¿¡æ¯
            total_params = sum(p.numel() for p in model.parameters())
            print(f"ğŸ“Š æ¨¡å‹å‚æ•°: {total_params:,}")
            
            # è¾“å‡ºç æœ¬ä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰
            if hasattr(model, 'codebooks') and hasattr(model.codebooks, 'num_groups'):
                print(f"ğŸ“Š ç æœ¬é…ç½®: {model.codebooks.num_groups}ç»„ Ã— {model.codebooks.codebook_size}ä¸ªç å­—")
            
            print("âœ… GCN reconstructor loaded successfully!")
            return model
            
        except Exception as e:
            print(f"âŒ åŠ è½½GCNé‡æ„å™¨å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            # è¿”å›Noneè€Œä¸æ˜¯å´©æºƒ
            return None
    
    def extract_skeleton_from_radar(self, radar_data):
        """ä»é›·è¾¾ç‰¹å¾å›¾æå–éª¨æ¶"""
        with torch.no_grad():
            # è½¬æ¢æ•°æ®æ ¼å¼ï¼š(B, H, W, C) -> (B, C, H, W)
            if len(radar_data.shape) == 4:
                radar_tensor = torch.from_numpy(radar_data.transpose(0, 3, 1, 2)).float().to(self.device)
            elif len(radar_data.shape) == 3:
                radar_tensor = torch.from_numpy(radar_data.transpose(2, 0, 1)).unsqueeze(0).float().to(self.device)
            else:
                raise ValueError(f"Unexpected radar data shape: {radar_data.shape}")
            
            # MARSéª¨æ¶æå–å™¨æ¨ç†
            mars_output = self.skeleton_extractor(radar_tensor)
            
            # æ£€æŸ¥è¾“å‡ºæ ¼å¼
            if len(mars_output.shape) == 2 and mars_output.shape[1] == 57:
                # MARSæ ¼å¼ï¼š(B, 57) = (x1...x19, y1...y19, z1...z19)
                # å‚ç…§vis_skeleton_extractor.pyçš„å¤„ç†æ–¹å¼
                batch_size = mars_output.shape[0]
                
                # é‡ç»„ä¸º(B, 19, 3)æ ¼å¼: ä»æ‰å¹³åŒ–çš„57ç»´é‡ç»„ä¸º19ä¸ªå…³èŠ‚ç‚¹
                x_coords = mars_output[:, 0:19]    # xåæ ‡: 0-18
                y_coords = mars_output[:, 19:38]   # yåæ ‡: 19-37  
                z_coords = mars_output[:, 38:57]   # zåæ ‡: 38-56
                mars_skeleton = torch.stack([x_coords, y_coords, z_coords], dim=-1)  # (B, 19, 3)
            else:
                # å‡è®¾å·²ç»æ˜¯(B, 19, 3)æ ¼å¼
                mars_skeleton = mars_output
            
            # ä½¿ç”¨æ˜ å°„å™¨è½¬æ¢ä¸ºNTU 25å…³èŠ‚ç‚¹
            # æ³¨æ„ï¼šæ˜ å°„å™¨éœ€è¦åŸå§‹57ç»´è¾“å‡ºï¼Œä¼šå†…éƒ¨å¤„ç†åæ ‡é‡ç»„
            ntu_skeleton = self.joint_mapper(mars_output)  # ä¼ å…¥åŸå§‹57ç»´è¾“å‡º
            
            return ntu_skeleton
    
    def reconstruct_skeleton_with_gcn(self, skeleton_data):
        """ä½¿ç”¨GCNç æœ¬é‡æ„éª¨æ¶"""
        if self.gcn_reconstructor is None:
            print("âŒ GCNé‡æ„å™¨æœªåŠ è½½")
            return None
            
        with torch.no_grad():
            # æ ‡å‡†åŒ–éª¨æ¶æ•°æ®ï¼ˆä¸GCNè®­ç»ƒæ—¶ä¸€è‡´ï¼‰
            normalized_skeleton = self._normalize_skeleton(skeleton_data)
            
            # è½¬æ¢ä¸ºå¼ é‡
            if isinstance(normalized_skeleton, np.ndarray):
                skeleton_tensor = torch.from_numpy(normalized_skeleton.astype(np.float32))
            else:
                skeleton_tensor = normalized_skeleton
            
            skeleton_tensor = skeleton_tensor.to(self.device)
            
            # GCNå‰å‘ä¼ æ’­
            try:
                output = self.gcn_reconstructor(skeleton_tensor, return_recon=True)
                
                # æå–ç»“æœ
                reconstructed_xzy = output['reconstructed'].cpu().numpy()
                token_sequence = output['token_sequence'].cpu().numpy()
                vq_loss = output['vq_loss'].item()
                
                # å‚ç…§gcn_skeleton_gif_visualizer.pyçš„å¤„ç†æ–¹å¼ï¼š
                # å¯¹é‡å»ºçš„éª¨æ¶è¿›è¡Œåæ ‡è½¬æ¢: (x,z,y) -> (x,y,z) ä»¥åŒ¹é…å¯è§†åŒ–
                reconstructed = reconstructed_xzy[:, :, [0, 2, 1]]  # [x,z,y] -> [x,y,z]
                
                # å°†å½’ä¸€åŒ–ç»“æœä¹Ÿè½¬æ¢å›(x,y,z)æ ¼å¼ä»¥ä¿æŒä¸€è‡´æ€§
                normalized_xyz = normalized_skeleton[:, :, [0, 2, 1]]  # [x,z,y] -> [x,y,z]
                
                return {
                    'original': skeleton_data,
                    'normalized': normalized_xyz,
                    'reconstructed': reconstructed,
                    'token_sequence': token_sequence,
                    'vq_loss': vq_loss,
                    'group_results': output.get('group_results', {})
                }
                
            except Exception as e:
                print(f"âŒ GCNé‡æ„è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
                return None
    
    def _normalize_skeleton(self, skeleton):
        """æ ‡å‡†åŒ–éª¨æ¶æ•°æ®ï¼ˆä¸GCNè®­ç»ƒæ—¶ä¿æŒä¸€è‡´ï¼‰
        
        å…³é”®ä¿®æ­£ï¼špipelineä¸­çš„skeletonæ•°æ®æ¥è‡ªMARSâ†’NTUæ˜ å°„å™¨ï¼Œ
        å·²ç»æ˜¯NTUæ ‡å‡†çš„(x,y,z)æ ¼å¼ï¼Œä½†GCNæ¨¡å‹æœŸæœ›(x,z,y)æ ¼å¼è¾“å…¥
        """
        if isinstance(skeleton, torch.Tensor):
            skeleton = skeleton.cpu().numpy()
        
        normalized_skeletons = []
        for i in range(skeleton.shape[0]):
            single_skeleton = skeleton[i]
            
            # MARSæ˜ å°„å™¨è¾“å‡ºçš„æ˜¯æ ‡å‡†NTUæ ¼å¼(x,y,z)
            # éœ€è¦è½¬æ¢ä¸ºGCNè®­ç»ƒæ—¶ä½¿ç”¨çš„(x,z,y)æ ¼å¼
            single_skeleton_xzy = single_skeleton[:, [0, 2, 1]]  # [x,y,z] -> [x,z,y]
            
            # ç¦ç”¨éª¨æ¶å¯¹é½ï¼Œå› ä¸ºå®ƒå¯èƒ½å¯¼è‡´å€’ç«‹é—®é¢˜
            aligned = single_skeleton_xzy  # ç›´æ¥ä½¿ç”¨åŸå§‹æ–¹å‘
            # aligned = self._align_skeleton_orientation(single_skeleton_xzy)
            
            # ä½¿ç”¨ä¸è®­ç»ƒæ—¶ä¸€è‡´çš„æ ‡å‡†åŒ–æ–¹æ³•
            normalized = self._normalize_single_skeleton(aligned)
                
            normalized_skeletons.append(normalized)
        
        return np.array(normalized_skeletons)
    
    def _align_skeleton_orientation(self, skeleton):
        """å¯¹é½éª¨æ¶æ–¹å‘ï¼Œå‡å°‘æ—‹è½¬å¯¼è‡´çš„é‡å»ºé”™è¯¯
        
        å®Œå…¨å¤åˆ¶gcn_skeleton_visualizer.pyçš„é€»è¾‘ä»¥ç¡®ä¿ä¸€è‡´æ€§
        """
        # è®¡ç®—ä¸»è¦èº«ä½“è½´å‘ï¼ˆä»éª¨ç›†åˆ°å¤´éƒ¨ï¼‰
        # NTU RGB+Då…³èŠ‚ç‚¹ç´¢å¼•ï¼š0=éª¨ç›†ä¸­å¿ƒ, 3=å¤´é¡¶
        if len(skeleton) >= 4:
            pelvis = skeleton[0]  # éª¨ç›†ä¸­å¿ƒ
            head = skeleton[3]   # å¤´é¡¶

            # è®¡ç®—èº«ä½“ä¸»è½´
            body_axis = head - pelvis
            body_axis_norm = np.linalg.norm(body_axis)

            if body_axis_norm > 1e-6:
                # åœ¨(x,z,y)æ ¼å¼ä¸­ï¼ŒZè½´(ç´¢å¼•1)æ˜¯å‚ç›´æ–¹å‘
                # å°†èº«ä½“ä¸»è½´å¯¹é½åˆ°Zè½´æ­£æ–¹å‘(å‘ä¸Š)
                target_axis = np.array([0, 1, 0])  # åœ¨(x,z,y)æ ¼å¼ä¸­å¯¹åº”Zè½´(å‚ç›´å‘ä¸Š)
                body_axis_normalized = body_axis / body_axis_norm

                # è®¡ç®—æ—‹è½¬è§’åº¦
                cos_angle = np.dot(body_axis_normalized, target_axis)
                cos_angle = np.clip(cos_angle, -1.0, 1.0)

                # å¦‚æœèº«ä½“è½´å‘ä¸Zè½´ç›¸åï¼ˆå€’ç«‹ï¼‰ï¼Œè¿›è¡Œ180åº¦æ—‹è½¬
                if cos_angle < -0.5:  # è§’åº¦å¤§äº120åº¦ï¼Œè®¤ä¸ºæ˜¯å€’ç«‹
                    # ç»•Xè½´æ—‹è½¬180åº¦ç¿»æ­£éª¨æ¶
                    rotation_matrix = np.array([
                        [1, 0, 0],
                        [0, -1, 0],
                        [0, 0, -1]
                    ])
                    skeleton = np.dot(skeleton, rotation_matrix.T)

        return skeleton
    
    def _normalize_single_skeleton(self, skeleton):
        """æ ‡å‡†åŒ–å•ä¸ªéª¨æ¶"""
        # è®¡ç®—è´¨å¿ƒ
        centroid = np.mean(skeleton, axis=0)
        centered = skeleton - centroid
        
        # ä½¿ç”¨æœ€å¤§è·ç¦»è¿›è¡Œç¼©æ”¾ï¼ˆä¸è®­ç»ƒæ—¶ä¸€è‡´ï¼‰
        distances = np.sqrt(np.sum(centered**2, axis=1))
        max_distance = np.max(distances)
        
        if max_distance > 0:
            normalized = centered / max_distance
        else:
            normalized = centered
            
        return normalized
    
    def _denormalize_skeleton(self, normalized_skeleton, reference_skeleton):
        """å°†æ ‡å‡†åŒ–çš„éª¨æ¶åå˜æ¢åˆ°åŸå§‹åæ ‡ç©ºé—´
        
        Args:
            normalized_skeleton: æ ‡å‡†åŒ–çš„éª¨æ¶æ•°æ®
            reference_skeleton: å‚è€ƒçš„åŸå§‹éª¨æ¶ï¼ˆç”¨äºè·å–æ ‡å‡†åŒ–å‚æ•°ï¼‰
        
        Returns:
            åæ ‡å‡†åŒ–åçš„éª¨æ¶æ•°æ®
        """
        # ç¡®ä¿æ•°æ®æ˜¯numpyæ•°ç»„
        if isinstance(normalized_skeleton, torch.Tensor):
            normalized_skeleton = normalized_skeleton.cpu().numpy()
        if isinstance(reference_skeleton, torch.Tensor):
            reference_skeleton = reference_skeleton.cpu().numpy()
        
        # è®¡ç®—å‚è€ƒéª¨æ¶çš„æ ‡å‡†åŒ–å‚æ•°
        reference_centroid = np.mean(reference_skeleton, axis=0)
        reference_centered = reference_skeleton - reference_centroid
        reference_distances = np.sqrt(np.sum(reference_centered**2, axis=1))
        reference_max_distance = np.max(reference_distances)
        
        # åå˜æ¢ï¼šå…ˆä¹˜ä»¥æœ€å¤§è·ç¦»ï¼Œå†åŠ ä¸Šè´¨å¿ƒ
        if reference_max_distance > 0:
            denormalized = normalized_skeleton * reference_max_distance + reference_centroid
        else:
            denormalized = normalized_skeleton + reference_centroid
            
        return denormalized
    
    def process_complete_pipeline(self, radar_feature_map):
        """å®Œæ•´çš„å¤„ç†æµç¨‹ï¼šé›·è¾¾ â†’ éª¨æ¶æå– â†’ GCNé‡æ„"""
        print("ğŸ”„ æ‰§è¡Œå®Œæ•´å¤„ç†æµç¨‹...")
        
        # æ­¥éª¤1ï¼šä»é›·è¾¾æ•°æ®æå–éª¨æ¶
        print("  1ï¸âƒ£ ä»é›·è¾¾ç‰¹å¾å›¾æå–éª¨æ¶...")
        extracted_skeleton = self.extract_skeleton_from_radar(radar_feature_map)
        print(f"     âœ… æå–éª¨æ¶å½¢çŠ¶: {extracted_skeleton.shape}")
        
        # æ­¥éª¤2ï¼šä½¿ç”¨GCNé‡æ„éª¨æ¶
        print("  2ï¸âƒ£ ä½¿ç”¨GCNç æœ¬é‡æ„éª¨æ¶...")
        reconstruction_result = self.reconstruct_skeleton_with_gcn(extracted_skeleton)
        print(f"     âœ… é‡æ„å®Œæˆï¼ŒVQæŸå¤±: {reconstruction_result['vq_loss']:.6f}")
        
        # æ­¥éª¤3ï¼šç”Ÿæˆæ–‡æœ¬æè¿°
        text_description = None
        if self.text_mapper is not None and reconstruction_result is not None:
            print("  3ï¸âƒ£ ç”ŸæˆåŠ¨ä½œæ–‡æœ¬æè¿°...")
            try:
                token_sequence = reconstruction_result['token_sequence']
                if token_sequence.ndim > 1:
                    token_sequence = token_sequence.flatten()
                
                # ç¡®ä¿tokenåºåˆ—é•¿åº¦ä¸º5
                if len(token_sequence) >= 5:
                    token_list = token_sequence[:5].astype(int).tolist()
                    text_description = self.text_mapper.map_tokens_to_text(token_list)
                    print(f"     âœ… æ–‡æœ¬æè¿°: {text_description['natural_language']}")
                else:
                    print(f"     âš ï¸ Tokenåºåˆ—é•¿åº¦ä¸è¶³: {len(token_sequence)}")
                    
            except Exception as e:
                print(f"     âš ï¸ æ–‡æœ¬æè¿°ç”Ÿæˆå¤±è´¥: {e}")
        
        return {
            'radar_input': radar_feature_map,
            'extracted_skeleton': extracted_skeleton,
            'reconstruction_result': reconstruction_result,
            'text_description': text_description
        }
    
    def visualize_results(self, pipeline_results_list, save_path):
        """å¯è§†åŒ–å¤šä¸ªæ ·æœ¬çš„æµç¨‹ç»“æœ"""
        print(f"ğŸ¨ ç”Ÿæˆå¤šæ ·æœ¬å¯è§†åŒ–ç»“æœ...")
        
        num_samples = len(pipeline_results_list)
        # åˆ›å»º2x2ç½‘æ ¼ï¼Œæ¯ä¸ªæ ·æœ¬æ˜¾ç¤º4ä¸ªå­å›¾ï¼š3ä¸ªéª¨æ¶+1ä¸ªè¯¯å·®
        fig = plt.figure(figsize=(20, 16))
        
        for sample_idx, pipeline_result in enumerate(pipeline_results_list):
            extracted_skeleton = pipeline_result['extracted_skeleton'][0]  # å–ç¬¬ä¸€ä¸ªæ ·æœ¬
            reconstruction_result = pipeline_result['reconstruction_result']
            normalized_skeleton = reconstruction_result['normalized'][0]  # MARSæ ‡ç­¾éª¨æ¶ï¼ˆå½’ä¸€åŒ–åï¼‰
            reconstructed_skeleton = reconstruction_result['reconstructed'][0]
            
            # ä¸ºæ¯ä¸ªæ ·æœ¬åˆ›å»º4ä¸ªå­å›¾
            base_idx = sample_idx * 4
            
            # 1. MARSæ ‡ç­¾éª¨æ¶ï¼ˆå½’ä¸€åŒ–ï¼‰
            ax1 = fig.add_subplot(num_samples, 4, base_idx + 1, projection='3d')
            self._plot_skeleton_3d(ax1, normalized_skeleton, f'Sample {sample_idx+1}: MARS Label Skeleton', 'blue')
            
            # 2. æå–éª¨æ¶ï¼ˆåŸå§‹ï¼‰
            ax2 = fig.add_subplot(num_samples, 4, base_idx + 2, projection='3d')
            self._plot_skeleton_3d(ax2, extracted_skeleton, f'Sample {sample_idx+1}: Extracted Skeleton', 'green')
            
            # 3. é‡æ„éª¨æ¶
            ax3 = fig.add_subplot(num_samples, 4, base_idx + 3, projection='3d')
            self._plot_skeleton_3d(ax3, reconstructed_skeleton, f'Sample {sample_idx+1}: Reconstructed Skeleton', 'red')
            
            # 4. å…³èŠ‚é‡å»ºæŸå¤±
            ax4 = fig.add_subplot(num_samples, 4, base_idx + 4)
            errors = np.sqrt(np.sum((normalized_skeleton - reconstructed_skeleton)**2, axis=1))
            bars = ax4.bar(range(len(errors)), errors)
            ax4.set_title(f'Sample {sample_idx+1}: Joint Reconstruction Errors', fontsize=10, fontweight='bold')
            ax4.set_xlabel('Joint Index')
            ax4.set_ylabel('Error (L2)')
            
            # ä¸ºè¯¯å·®é«˜çš„å…³èŠ‚ç‚¹æ ‡è®°é¢œè‰²
            max_error = np.max(errors)
            for i, bar in enumerate(bars):
                if errors[i] > max_error * 0.7:
                    bar.set_color('red')
                elif errors[i] > max_error * 0.4:
                    bar.set_color('orange')
                else:
                    bar.set_color('green')
        
        # è®¡ç®—æ€»ä½“ç»Ÿè®¡ä¿¡æ¯
        all_recon_mse_errors = []
        all_real_world_mse_errors = []  # æ·»åŠ å®é™…åæ ‡ç©ºé—´çš„MSE
        all_vq_losses = []
        all_max_errors = []
        all_mean_errors = []
        
        for pipeline_result in pipeline_results_list:
            reconstruction_result = pipeline_result['reconstruction_result']
            normalized_skeleton = reconstruction_result['normalized'][0]
            reconstructed_skeleton = reconstruction_result['reconstructed'][0]
            original_skeleton = reconstruction_result['original'][0]  # åŸå§‹æå–çš„éª¨æ¶
            
            # ç¡®ä¿æ‰€æœ‰æ•°æ®éƒ½æ˜¯numpyæ•°ç»„
            if isinstance(normalized_skeleton, torch.Tensor):
                normalized_skeleton = normalized_skeleton.cpu().numpy()
            if isinstance(reconstructed_skeleton, torch.Tensor):
                reconstructed_skeleton = reconstructed_skeleton.cpu().numpy()
            if isinstance(original_skeleton, torch.Tensor):
                original_skeleton = original_skeleton.cpu().numpy()
            
            # æ ‡å‡†åŒ–ç©ºé—´ä¸­çš„MSEï¼ˆè®­ç»ƒæ—¶çš„è¯„ä¼°æŒ‡æ ‡ï¼‰
            recon_mse_error = np.mean((normalized_skeleton - reconstructed_skeleton)**2)
            
            # å®é™…åæ ‡ç©ºé—´çš„MSEï¼ˆæ›´ç›´è§‚çš„è¯¯å·®è¡¨ç¤ºï¼‰
            # å°†é‡æ„éª¨æ¶åå˜æ¢åˆ°åŸå§‹åæ ‡ç©ºé—´è¿›è¡Œæ¯”è¾ƒ
            reconstructed_original = self._denormalize_skeleton(reconstructed_skeleton, original_skeleton)
            real_world_mse_error = np.mean((original_skeleton - reconstructed_original)**2)
            
            vq_loss = reconstruction_result['vq_loss']
            errors = np.sqrt(np.sum((normalized_skeleton - reconstructed_skeleton)**2, axis=1))
            
            all_recon_mse_errors.append(recon_mse_error)
            all_real_world_mse_errors.append(real_world_mse_error)
            all_vq_losses.append(vq_loss)
            all_max_errors.append(np.max(errors))
            all_mean_errors.append(np.mean(errors))
        
        # æ·»åŠ æ•´ä½“æ ‡é¢˜ - æ˜¾ç¤ºä¸¤ç§MSE
        avg_recon_mse = np.mean(all_recon_mse_errors)
        avg_real_world_mse = np.mean(all_real_world_mse_errors)
        avg_vq = np.mean(all_vq_losses)
        plt.suptitle(f'Multi-Sample Skeleton Analysis ({num_samples} samples)\\n'
                    f'Normalized MSE: {avg_recon_mse:.6f} | Real-World MSE: {avg_real_world_mse:.4f} | VQ Loss: {avg_vq:.6f}', 
                    fontsize=16, fontweight='bold')
        
        plt.tight_layout(rect=[0, 0, 1, 0.95])
        
        # ä¿å­˜å›¾åƒ
        plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white')
        plt.close()
        
        print(f"âœ… Multi-sample visualization saved: {save_path}")
        
        return {
            'recon_mse_error': float(np.mean(all_recon_mse_errors)),
            'real_world_mse_error': float(np.mean(all_real_world_mse_errors)),
            'vq_loss': float(np.mean(all_vq_losses)),
            'max_joint_error': float(np.mean(all_max_errors)),
            'mean_joint_error': float(np.mean(all_mean_errors)),
            'sample_details': [
                {
                    'recon_mse_error': float(all_recon_mse_errors[i]),
                    'real_world_mse_error': float(all_real_world_mse_errors[i]),
                    'vq_loss': float(all_vq_losses[i]),
                    'max_joint_error': float(all_max_errors[i]),
                    'mean_joint_error': float(all_mean_errors[i])
                } for i in range(num_samples)
            ]
        }
    
    def _plot_skeleton_3d(self, ax, skeleton, title, color):
        """ç»˜åˆ¶3Déª¨æ¶ï¼Œç‰¹åˆ«å¤„ç†MARSæ˜ å°„çš„6ä¸ªé¢å¤–å…³èŠ‚ç‚¹"""
        # ç¡®ä¿skeletonæ˜¯numpyæ•°ç»„
        if isinstance(skeleton, torch.Tensor):
            skeleton = skeleton.cpu().numpy()
        
        # ä¿®æ­£å¯è§†åŒ–æ–¹å‘ï¼šåè½¬Zè½´ä»¥æ”¹å–„è§†è§’
        skeleton = skeleton.copy()  # é¿å…ä¿®æ”¹åŸå§‹æ•°æ®
        skeleton[:, 2] = -skeleton[:, 2]  # åè½¬Zè½´æ”¹å–„è§†è§’
        
        # ç»˜åˆ¶éª¨éª¼è¿æ¥
        for edge in self.skeleton_edges:
            if edge[0] < len(skeleton) and edge[1] < len(skeleton):
                start = skeleton[edge[0]]
                end = skeleton[edge[1]]
                if not (np.all(start == 0) or np.all(end == 0)):
                    ax.plot3D([start[0], end[0]], [start[1], end[1]], [start[2], end[2]],
                             color=color, alpha=0.8, linewidth=2.0)
        
        # ç»˜åˆ¶æ‰€æœ‰25ä¸ªå…³èŠ‚ç‚¹ï¼ˆç»Ÿä¸€æ ·å¼ï¼‰
        for i in range(len(skeleton)):
            joint = skeleton[i]
            if not np.all(joint == 0):
                ax.scatter(joint[0], joint[1], joint[2],
                          c=color, s=25, alpha=0.9, edgecolors='white', linewidth=0.5)
        
        ax.set_title(title, fontsize=12, fontweight='bold')
        ax.set_xlabel('X')
        ax.set_ylabel('Y')
        ax.set_zlabel('Z')
        
        # è®¾ç½®ç­‰æ¯”ä¾‹åæ ‡èŒƒå›´
        valid_joints = skeleton[~np.all(skeleton == 0, axis=1)]
        if len(valid_joints) > 0:
            # è®¡ç®—éª¨æ¶çš„å®é™…èŒƒå›´
            min_coords = np.min(valid_joints, axis=0)
            max_coords = np.max(valid_joints, axis=0)
            center = np.mean(valid_joints, axis=0)
            
            # è®¡ç®—æœ€å¤§èŒƒå›´ä»¥ç¡®ä¿ç­‰æ¯”ä¾‹
            ranges = max_coords - min_coords
            max_range = max(np.max(ranges) / 2, 0.3)  # æœ€å°èŒƒå›´0.3
            
            # è®¾ç½®ç­‰æ¯”ä¾‹åæ ‡è½´
            ax.set_xlim([center[0] - max_range, center[0] + max_range])
            ax.set_ylim([center[1] - max_range, center[1] + max_range])
            ax.set_zlim([center[2] - max_range, center[2] + max_range])
            
            # å¼ºåˆ¶ç­‰æ¯”ä¾‹ - å‚ç…§ä¸¤ä¸ªå‚è€ƒæ–‡ä»¶çš„è®¾ç½®æ–¹å¼
            ax.set_box_aspect([1,1,1])
        
        # å‚è€ƒgcn_skeleton_gif_visualizer.pyçš„è§†è§’è®¾ç½®
        ax.view_init(elev=15, azim=45)
    
    def generate_individual_sample_visualizations(self, pipeline_results, output_dir):
        """ä¸ºæ¯ä¸ªæ ·æœ¬ç”Ÿæˆå•ç‹¬çš„å¯è§†åŒ–å›¾ç‰‡"""
        print(f"ğŸ–¼ï¸ ç”Ÿæˆå•ç‹¬æ ·æœ¬å¯è§†åŒ–...")
        
        individual_metrics = []
        
        for i, result in enumerate(pipeline_results):
            sample_idx = i + 1
            
            # æå–æ•°æ® - ç¡®ä¿æ‰€æœ‰æ•°æ®éƒ½è½¬æ¢ä¸ºnumpy
            radar_input = result['radar_input']
            extracted_skeleton = result['extracted_skeleton'][0].cpu().numpy() if isinstance(result['extracted_skeleton'], torch.Tensor) else result['extracted_skeleton'][0]
            reconstructed_skeleton = result['reconstruction_result']['reconstructed'][0]
            normalized_skeleton = result['reconstruction_result']['normalized'][0]
            original_skeleton = result['reconstruction_result']['original'][0]
            
            # ç¡®ä¿æ‰€æœ‰éª¨æ¶æ•°æ®éƒ½æ˜¯numpyæ•°ç»„
            if isinstance(reconstructed_skeleton, torch.Tensor):
                reconstructed_skeleton = reconstructed_skeleton.cpu().numpy()
            if isinstance(normalized_skeleton, torch.Tensor):
                normalized_skeleton = normalized_skeleton.cpu().numpy()
            if isinstance(original_skeleton, torch.Tensor):
                original_skeleton = original_skeleton.cpu().numpy()
            
            # è®¡ç®—æ ‡å‡†åŒ–ç©ºé—´çš„çœŸæ­£é‡æ„è¯¯å·®ï¼ˆä¸è®­ç»ƒæ—¶ä¸€è‡´ï¼‰
            normalized_recon_mse = np.mean((normalized_skeleton - reconstructed_skeleton) ** 2)
            
            # è®¡ç®—å®é™…åæ ‡ç©ºé—´çš„é‡æ„è¯¯å·®ï¼ˆæ›´ç›´è§‚ï¼‰
            reconstructed_original = self._denormalize_skeleton(reconstructed_skeleton, original_skeleton)
            real_world_recon_mse = np.mean((original_skeleton - reconstructed_original) ** 2)
            
            # è®¡ç®—æå–-é‡æ„å·®å¼‚ï¼ˆä»…ç”¨äºè°ƒè¯•ï¼Œæ ‡å‡†åŒ–extracted_skeletonåæ¯”è¾ƒï¼‰
            extracted_normalized = self._normalize_skeleton(extracted_skeleton.reshape(1, 25, 3))[0]
            extraction_recon_mse = np.mean((extracted_normalized - reconstructed_skeleton) ** 2)
            
            joint_errors = np.sqrt(np.sum((normalized_skeleton - reconstructed_skeleton) ** 2, axis=1))
            max_joint_error = np.max(joint_errors)
            mean_joint_error = np.mean(joint_errors)
            
            # è·å–VQæŸå¤±
            vq_loss = result['reconstruction_result'].get('vq_loss', 0.0)
            
            # åˆ›å»ºå•ç‹¬çš„å›¾å½¢ - 1è¡Œ3åˆ—å¸ƒå±€
            fig = plt.figure(figsize=(18, 6))
            
            # è®¾ç½®ä¸­æ–‡å­—ä½“
            plt.rcParams['font.sans-serif'] = ['DejaVu Sans']
            plt.rcParams['axes.unicode_minus'] = False
            
            # é›·è¾¾è¾“å…¥å¯è§†åŒ– (æ˜¾ç¤ºé›·è¾¾ç‰¹å¾å›¾ä¿¡æ¯)
            ax1 = fig.add_subplot(131, projection='3d')
            # ç”±äºåŸå§‹éª¨æ¶æ•°æ®ä¸ç›´æ¥å¯ç”¨ï¼Œæ˜¾ç¤ºé›·è¾¾è¾“å…¥çš„ç»´åº¦ä¿¡æ¯
            ax1.text(0.5, 0.5, 0.5, f'é›·è¾¾ç‰¹å¾å›¾\n{radar_input.shape}', ha='center', va='center', fontsize=14,
                    bbox=dict(boxstyle="round,pad=0.3", facecolor="lightblue", alpha=0.8))
            ax1.set_title(f'æ ·æœ¬ {sample_idx}: é›·è¾¾è¾“å…¥', fontsize=12, fontweight='bold')
            ax1.set_xlim([0, 1])
            ax1.set_ylim([0, 1])
            ax1.set_zlim([0, 1])
            
            # Extracted skeleton
            ax2 = fig.add_subplot(132, projection='3d')
            self._plot_skeleton_3d(ax2, extracted_skeleton, f'Sample {sample_idx}: Extracted', 'green')
            
            # Reconstructed skeleton 
            ax3 = fig.add_subplot(133, projection='3d')
            self._plot_skeleton_3d(ax3, reconstructed_skeleton, f'Sample {sample_idx}: GCN Reconstructed', 'red')
            
            # æ·»åŠ è¯¯å·®ä¿¡æ¯ - æ˜ç¡®æ˜¾ç¤ºä¸¤ç§MSEï¼Œä¸»è¦å…³æ³¨æ ‡å‡†åŒ–MSEï¼ˆä¸è®­ç»ƒæ—¶ä¸€è‡´ï¼‰
            fig.suptitle(f'æ ·æœ¬ {sample_idx} - éª¨æ¶æå–ä¸é‡æ„å¯¹æ¯”\n'
                        f'æ ‡å‡†åŒ–MSE: {normalized_recon_mse:.6f} | å®é™…åæ ‡MSE: {real_world_recon_mse:.4f} | æå–-é‡æ„MSE: {extraction_recon_mse:.6f}',
                        fontsize=16, fontweight='bold', y=0.95)
            
            # æ·»åŠ å¤„ç†ä¿¡æ¯
            info_text = f"Radar Input: {radar_input.shape} -> Extracted: {extracted_skeleton.shape} -> Reconstructed: {reconstructed_skeleton.shape}"
            
            fig.text(0.02, 0.02, info_text, fontsize=9, 
                    bbox=dict(boxstyle="round,pad=0.4", facecolor="lightblue", alpha=0.9),
                    verticalalignment='bottom')
            
            plt.tight_layout()
            
            # ä¿å­˜å›¾ç‰‡
            save_path = os.path.join(output_dir, f'extraction_reconstruction_sample_{sample_idx:02d}.png')
            plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white', edgecolor='none')
            plt.close()
            
            print(f"âœ… å·²ä¿å­˜æ ·æœ¬ {sample_idx:02d}: {os.path.basename(save_path)}")
            
            individual_metrics.append({
                'sample_id': sample_idx,
                'normalized_recon_mse': normalized_recon_mse,  # ä¸»è¦æŒ‡æ ‡ï¼šä¸è®­ç»ƒæ—¶ä¸€è‡´çš„æ ‡å‡†åŒ–MSE
                'real_world_recon_mse': real_world_recon_mse,  # è¾…åŠ©æŒ‡æ ‡ï¼šå®é™…åæ ‡ç©ºé—´MSE
                'extraction_recon_mse': extraction_recon_mse,  # è°ƒè¯•æŒ‡æ ‡ï¼šæå–-é‡æ„MSE
                'vq_loss': vq_loss,
                'max_joint_error': max_joint_error,
                'mean_joint_error': mean_joint_error,
                'file_path': save_path
            })
        
        return individual_metrics
    
    def generate_sequence_gif_animations(self, radar_data_path, output_dir, num_sequences=5, frames_per_sequence=8, fps=3):
        """ç”Ÿæˆç›¸é‚»å‡ å¸§çš„GIFåŠ¨ç”»å±•ç¤ºé‡æ„è¿‡ç¨‹
        
        Args:
            radar_data_path: é›·è¾¾æ•°æ®è·¯å¾„
            output_dir: GIFä¿å­˜ç›®å½•
            num_sequences: ç”Ÿæˆåºåˆ—æ•°é‡
            frames_per_sequence: æ¯ä¸ªåºåˆ—çš„å¸§æ•°
            fps: GIFå¸§ç‡
        """
        print(f"ğŸ¬ ç”Ÿæˆéª¨æ¶é‡æ„GIFåŠ¨ç”»...")
        
        # åˆ›å»ºGIFè¾“å‡ºç›®å½•
        gif_output_dir = os.path.join(output_dir, "../skeleton_extraction_gif_reconstruction_new")
        os.makedirs(gif_output_dir, exist_ok=True)
        
        # åŠ è½½å®Œæ•´çš„é›·è¾¾æ•°æ®
        if not os.path.exists(radar_data_path):
            print(f"âŒ é›·è¾¾æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {radar_data_path}")
            return []
        
        # åŠ è½½æ ‡ç­¾æ•°æ®
        labels_path = '/home/uo/myProject/HumanPoint-BERT/data/MARS/labels_test.npy'
        if not os.path.exists(labels_path):
            print(f"âŒ æ ‡ç­¾æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {labels_path}")
            return []
        
        full_data = np.load(radar_data_path)
        label_data = np.load(labels_path)
        print(f"âœ… åŠ è½½å®Œæ•´é›·è¾¾æ•°æ®: {full_data.shape}")
        print(f"âœ… åŠ è½½æ ‡ç­¾æ•°æ®: {label_data.shape}")
        
        gif_info_list = []
        
        # ç”Ÿæˆå¤šä¸ªåºåˆ—çš„GIF
        for seq_idx in range(num_sequences):
            # ä¸ºæ¯ä¸ªåºåˆ—é€‰æ‹©ä¸åŒçš„èµ·å§‹ä½ç½®
            start_idx = seq_idx * (len(full_data) // (num_sequences + 1))
            end_idx = min(start_idx + frames_per_sequence, len(full_data))
            
            if end_idx - start_idx < frames_per_sequence:
                # å¦‚æœæ•°æ®ä¸å¤Ÿï¼Œä»æœ«å°¾å‘å‰å–
                end_idx = len(full_data) - 1
                start_idx = max(0, end_idx - frames_per_sequence + 1)
            
            print(f"ğŸ“¹ ç”Ÿæˆåºåˆ— {seq_idx+1}/{num_sequences}: å¸§ {start_idx}-{end_idx-1}")
            
            # æå–åºåˆ—æ•°æ®
            sequence_data = full_data[start_idx:end_idx]
            sequence_labels = label_data[start_idx:end_idx]
            
            # å¤„ç†åºåˆ—ä¸­çš„æ¯ä¸€å¸§
            frame_results = []
            for frame_idx, (radar_frame, label_frame) in enumerate(zip(sequence_data, sequence_labels)):
                # å¤„ç†å•å¸§
                frame_result = self.process_complete_pipeline(radar_frame.reshape(1, 8, 8, 5))
                
                # æå–é‡æ„ç»“æœ
                try:
                    vq_loss = frame_result['reconstruction_result']['vq_loss']
                except:
                    vq_loss = 0.0
                
                frame_results.append({
                    'frame_idx': frame_idx,
                    'label': label_frame,  # æ·»åŠ æ ‡ç­¾æ•°æ®
                    'extracted': frame_result['extracted_skeleton'][0].cpu().numpy(),
                    'reconstructed': frame_result['reconstruction_result']['reconstructed'][0],
                    'vq_loss': vq_loss
                })
            
            # ç”ŸæˆGIF
            gif_path = os.path.join(gif_output_dir, f'skeleton_reconstruction_sequence_{seq_idx+1:02d}.gif')
            gif_info = self._create_skeleton_sequence_gif(frame_results, gif_path, fps)
            gif_info['sequence_id'] = seq_idx + 1
            gif_info['start_frame'] = start_idx
            gif_info['end_frame'] = end_idx - 1
            gif_info_list.append(gif_info)
            
        return gif_info_list
    
    def _create_skeleton_sequence_gif(self, frame_results, gif_path, fps=3):
        """åˆ›å»ºå•ä¸ªåºåˆ—çš„éª¨æ¶é‡æ„GIFåŠ¨ç”»"""
        
        num_frames = len(frame_results)
        if num_frames == 0:
            return {'success': False, 'path': gif_path}
        
        # åˆ›å»ºå›¾å½¢å¸ƒå±€: 1è¡Œ3åˆ—
        fig = plt.figure(figsize=(24, 8))
        
        # è®¾ç½®ä¸­æ–‡å­—ä½“æ”¯æŒ
        plt.rcParams['font.sans-serif'] = ['DejaVu Sans', 'SimHei', 'Arial Unicode MS', 'Droid Sans Fallback']
        plt.rcParams['axes.unicode_minus'] = False
        plt.rcParams['font.size'] = 10
        
        def animate(frame_idx):
            """åŠ¨ç”»æ›´æ–°å‡½æ•°"""
            fig.clear()
            
            # è·å–å½“å‰å¸§æ•°æ®
            current_frame = frame_results[frame_idx]
            label = current_frame['label']
            extracted = current_frame['extracted']
            reconstructed = current_frame['reconstructed']
            vq_loss = current_frame['vq_loss']
            
            # å°†æ ‡ç­¾æ•°æ®ä»MARS 57ç»´æ ¼å¼è½¬æ¢ä¸ºNTU 25å…³èŠ‚æ ¼å¼ï¼Œä¸æå–éª¨æ¶ä¿æŒä¸€è‡´
            def convert_mars_to_ntu_format(mars_57_data):
                """å°†MARS 57ç»´æ•°æ®è½¬æ¢ä¸ºNTU 25å…³èŠ‚æ ¼å¼ï¼Œå¤ç”¨ç°æœ‰çš„æ˜ å°„å™¨"""
                # ä½¿ç”¨å…³èŠ‚æ˜ å°„å™¨å°†MARSæ•°æ®è½¬æ¢ä¸ºNTUæ ¼å¼
                mars_tensor = torch.tensor(mars_57_data).unsqueeze(0).float().to(self.device)
                ntu_skeleton = self.joint_mapper(mars_tensor)
                return ntu_skeleton[0].detach().cpu().numpy()  # è¿”å›(25, 3)æ ¼å¼
            
            # è½¬æ¢æ ‡ç­¾æ•°æ®ä¸ºNTUæ ¼å¼
            label_ntu = convert_mars_to_ntu_format(label)
            
            # æ­£ç¡®çš„MSEè®¡ç®—æ–¹å¼ï¼š
            # 1. å°†æå–çš„éª¨æ¶æ ‡å‡†åŒ–åä¸é‡æ„éª¨æ¶æ¯”è¾ƒï¼ˆè¿™æ˜¯è®­ç»ƒæ—¶çš„è¯„ä¼°æ–¹å¼ï¼‰
            extracted_normalized = self._normalize_skeleton(extracted.reshape(1, 25, 3))[0]
            
            # ç¡®ä¿reconstructedæ•°æ®æ ¼å¼æ­£ç¡®
            if isinstance(reconstructed, torch.Tensor):
                reconstructed_array = reconstructed.cpu().numpy()
            else:
                reconstructed_array = reconstructed
            
            # ç¡®ä¿æ•°æ®å½¢çŠ¶ä¸€è‡´ï¼Œå¹¶ä¸”é‡æ„æ•°æ®å·²ç»æ˜¯æ ‡å‡†åŒ–çš„
            if reconstructed_array.shape != extracted_normalized.shape:
                if len(reconstructed_array.shape) == 1 and reconstructed_array.shape[0] == 75:
                    # å¦‚æœæ˜¯75ç»´æ‰å¹³åŒ–æ•°æ®ï¼Œé‡å¡‘ä¸º(25, 3)
                    reconstructed_array = reconstructed_array.reshape(25, 3)
                elif len(reconstructed_array.shape) == 2 and reconstructed_array.shape[0] == 1:
                    # å¦‚æœæ˜¯(1, 75)ï¼Œå…ˆå±•å¹³å†é‡å¡‘
                    reconstructed_array = reconstructed_array.flatten().reshape(25, 3)
                else:
                    print(f"è­¦å‘Šï¼šé‡æ„æ•°æ®å½¢çŠ¶ä¸åŒ¹é…: {reconstructed_array.shape} vs {extracted_normalized.shape}")
            
            # æ£€æŸ¥é‡æ„æ•°æ®æ˜¯å¦åœ¨åˆç†èŒƒå›´å†…ï¼ˆæ ‡å‡†åŒ–æ•°æ®åº”è¯¥åœ¨[0,1]èŒƒå›´å†…ï¼‰
            if reconstructed_array.min() < -0.1 or reconstructed_array.max() > 1.1:
                print(f"è­¦å‘Šï¼šé‡æ„æ•°æ®å¯èƒ½æœªæ ‡å‡†åŒ–ï¼ŒèŒƒå›´: [{reconstructed_array.min():.3f}, {reconstructed_array.max():.3f}]")
                # å¦‚æœé‡æ„æ•°æ®ä¸åœ¨æ ‡å‡†åŒ–èŒƒå›´å†…ï¼Œå¯èƒ½éœ€è¦é‡æ–°æ ‡å‡†åŒ–
                # ä½†è¿™é‡Œæˆ‘ä»¬å‡è®¾æ¨¡å‹è¾“å‡ºå·²ç»æ˜¯æ ‡å‡†åŒ–çš„
            
            # æ ‡å‡†åŒ–ç©ºé—´MSEï¼ˆä¸è®­ç»ƒæ—¶ä¸€è‡´çš„è¯„ä¼°æŒ‡æ ‡ï¼‰
            normalized_mse_error = np.mean((extracted_normalized - reconstructed_array) ** 2)
            
            # å®é™…åæ ‡ç©ºé—´çš„é‡æ„è¯¯å·®ï¼ˆå°†é‡æ„æ•°æ®åæ ‡å‡†åŒ–åæ¯”è¾ƒï¼‰
            try:
                # å°†é‡æ„éª¨æ¶åæ ‡å‡†åŒ–åˆ°åŸå§‹åæ ‡ç©ºé—´
                reconstructed_denormalized = self._denormalize_skeleton(reconstructed_array.reshape(1, 25, 3), extracted.reshape(1, 25, 3))[0]
                real_world_recon_error = np.mean((extracted - reconstructed_denormalized) ** 2)
                
                # è®¡ç®—Ground Truthä¸æå–éª¨æ¶çš„å·®å¼‚ï¼ˆå‚è€ƒï¼‰
                real_world_extraction_error = np.mean((label_ntu - extracted) ** 2)
            except Exception as e:
                print(f"è­¦å‘Šï¼šåæ ‡å‡†åŒ–å¤±è´¥: {e}")
                # å¤‡ç”¨è®¡ç®—ï¼šä½¿ç”¨æ ‡å‡†åŒ–ç©ºé—´çš„MSEä½œä¸ºå‚è€ƒ
                real_world_recon_error = normalized_mse_error
                real_world_extraction_error = normalized_mse_error
            
            # åˆ›å»ºå­å›¾: 3åˆ—å¸ƒå±€
            ax1 = fig.add_subplot(131, projection='3d')
            ax2 = fig.add_subplot(132, projection='3d') 
            ax3 = fig.add_subplot(133, projection='3d')
            
            # ç»˜åˆ¶æ ‡ç­¾éª¨æ¶ (Ground Truth) - ç°åœ¨ä½¿ç”¨ç›¸åŒçš„NTUæ ¼å¼å’Œç»˜åˆ¶å‡½æ•°
            self._plot_skeleton_3d(ax1, label_ntu, 
                                 f'Frame {frame_idx+1}/{num_frames}: Ground Truth', 'blue')
            
            # ç»˜åˆ¶æå–çš„éª¨æ¶
            self._plot_skeleton_3d(ax2, extracted, 
                                 f'Frame {frame_idx+1}/{num_frames}: Extracted Skeleton', 'green')
            
            # ç»˜åˆ¶é‡æ„çš„éª¨æ¶ - ä½¿ç”¨æ­£ç¡®çš„æ•°æ®æ ¼å¼
            if isinstance(reconstructed_array, np.ndarray) and reconstructed_array.shape == (25, 3):
                self._plot_skeleton_3d(ax3, reconstructed_array,
                                     f'Frame {frame_idx+1}/{num_frames}: Reconstructed Skeleton\nVQ Loss: {vq_loss:.4f}', 'red')
            else:
                # å¦‚æœæ•°æ®æ ¼å¼ä¸æ­£ç¡®ï¼Œå°è¯•åæ ‡å‡†åŒ–åˆ°åŸå§‹ç©ºé—´è¿›è¡Œæ˜¾ç¤º
                try:
                    reconstructed_denormalized = self._denormalize_skeleton(reconstructed_array.reshape(1, 25, 3), extracted.reshape(1, 25, 3))[0]
                    self._plot_skeleton_3d(ax3, reconstructed_denormalized,
                                         f'Frame {frame_idx+1}/{num_frames}: Reconstructed Skeleton\nVQ Loss: {vq_loss:.4f}', 'red')
                except:
                    # æœ€åçš„å¤‡ç”¨æ–¹æ¡ˆ
                    self._plot_skeleton_3d(ax3, reconstructed_array.reshape(25, 3),
                                         f'Frame {frame_idx+1}/{num_frames}: Reconstructed Skeleton\nVQ Loss: {vq_loss:.4f}', 'red')
            
            # æ„å»ºæ ‡é¢˜æ–‡æœ¬
            title_text = f'Complete Skeleton Reconstruction Pipeline\nFrame {frame_idx+1}/{num_frames} | Normalized MSE: {normalized_mse_error:.6f} | Real-world MSE: {real_world_recon_error:.4f}'
            
            fig.suptitle(title_text, fontsize=14, fontweight='bold', y=0.95)
            
            # è°ƒæ•´å¸ƒå±€
            plt.tight_layout()
        
        # åˆ›å»ºåŠ¨ç”»
        try:
            anim = FuncAnimation(fig, animate, frames=num_frames, interval=1000//fps, blit=False, repeat=True)
            
            # ä¿å­˜GIF
            writer = PillowWriter(fps=fps)
            anim.save(gif_path, writer=writer, dpi=150)
            plt.close(fig)
            
            print(f"âœ… GIFä¿å­˜æˆåŠŸ: {os.path.basename(gif_path)}")
            
            # è®¡ç®—åºåˆ—ç»Ÿè®¡ - ä¿®æ­£ï¼šä½¿ç”¨æ­£ç¡®çš„æ ‡å‡†åŒ–MSEè®¡ç®—
            normalized_mse_errors = []
            real_world_mse_errors = []  # å®é™…åæ ‡ç©ºé—´MSE
            vq_losses = [fr['vq_loss'] for fr in frame_results]
            
            for fr in frame_results:
                # æ ‡å‡†åŒ–MSEï¼šå°†æå–çš„éª¨æ¶æ ‡å‡†åŒ–åä¸é‡æ„éª¨æ¶æ¯”è¾ƒï¼ˆæ­£ç¡®çš„MSEï¼‰
                extracted_normalized = self._normalize_skeleton(fr['extracted'].reshape(1, 25, 3))[0]
                
                # ç¡®ä¿é‡æ„æ•°æ®æ ¼å¼æ­£ç¡®å¹¶ä¸”è½¬æ¢ä¸ºnumpy
                reconstructed_data = fr['reconstructed']
                if isinstance(reconstructed_data, torch.Tensor):
                    reconstructed_data = reconstructed_data.cpu().numpy()
                    
                # æ•°æ®å½¢çŠ¶æ£€æŸ¥å’Œä¿®æ­£
                if reconstructed_data.shape != (25, 3):
                    if len(reconstructed_data.shape) == 1 and reconstructed_data.shape[0] == 75:
                        reconstructed_data = reconstructed_data.reshape(25, 3)
                    elif len(reconstructed_data.shape) == 2 and reconstructed_data.shape[0] == 1:
                        reconstructed_data = reconstructed_data.flatten().reshape(25, 3)
                    else:
                        print(f"âš ï¸ è­¦å‘Šï¼šé‡æ„æ•°æ®å½¢çŠ¶å¼‚å¸¸: {reconstructed_data.shape}ï¼Œè·³è¿‡æ­¤å¸§")
                        continue
                        
                # æ•°æ®èŒƒå›´éªŒè¯ï¼šé‡æ„æ•°æ®åº”è¯¥åœ¨æ ‡å‡†åŒ–ç©ºé—´(-2, 2)èŒƒå›´å†…
                # æ³¨æ„ï¼šæ ‡å‡†åŒ–åçš„æ•°æ®ä¸ä¸€å®šåœ¨[0,1]ï¼Œè€Œæ˜¯åœ¨è´¨å¿ƒå½’é›¶ã€æœ€å¤§è·ç¦»å½’ä¸€åŒ–åçš„èŒƒå›´
                data_min, data_max = reconstructed_data.min(), reconstructed_data.max()
                if data_min < -2.0 or data_max > 2.0:
                    print(f"âš ï¸ è­¦å‘Šï¼šé‡æ„æ•°æ®èŒƒå›´ [{data_min:.3f}, {data_max:.3f}] è¶…å‡ºé¢„æœŸèŒƒå›´ [-2, 2]")
                    print(f"   è¿™å¯èƒ½è¡¨æ˜æ¨¡å‹è¾“å‡ºå¼‚å¸¸ï¼Œä½†ä»ç»§ç»­è®¡ç®—MSE")
                
                # è®¡ç®—æ ‡å‡†åŒ–MSEï¼ˆä¸»è¦è¯„ä¼°æŒ‡æ ‡ï¼Œä¸è®­ç»ƒæ—¶ä¸€è‡´ï¼‰
                normalized_mse = np.mean((extracted_normalized - reconstructed_data) ** 2)
                normalized_mse_errors.append(normalized_mse)
                
                # å®é™…åæ ‡ç©ºé—´MSEï¼šå°†é‡æ„éª¨æ¶åæ ‡å‡†åŒ–åä¸æå–éª¨æ¶æ¯”è¾ƒ
                try:
                    reconstructed_denormalized = self._denormalize_skeleton(
                        reconstructed_data.reshape(1, 25, 3), 
                        fr['extracted'].reshape(1, 25, 3)
                    )[0]
                    real_world_mse = np.mean((fr['extracted'] - reconstructed_denormalized) ** 2)
                    real_world_mse_errors.append(real_world_mse)
                except Exception as e:
                    print(f"è­¦å‘Šï¼šåæ ‡å‡†åŒ–å¤±è´¥: {e}")
                    # å¤‡ç”¨ï¼šä½¿ç”¨æ ‡å‡†åŒ–MSEä½œä¸ºè¿‘ä¼¼
                    real_world_mse_errors.append(normalized_mse * 1000)  # ç²—ç•¥è½¬æ¢
            
            return {
                'success': True,
                'path': gif_path,
                'num_frames': num_frames,
                'avg_normalized_mse': np.mean(normalized_mse_errors),  # ä¸»è¦æŒ‡æ ‡ï¼šæ ‡å‡†åŒ–MSE
                'avg_real_world_mse': np.mean(real_world_mse_errors) if real_world_mse_errors else 0.0,  # å®é™…åæ ‡MSE
                'avg_vq_loss': np.mean(vq_losses),
                'frame_range': (0, num_frames-1)
            }
            
        except Exception as e:
            import traceback
            error_details = traceback.format_exc()
            print(f"âŒ GIFç”Ÿæˆå¤±è´¥: {e}")
            print(f"è¯¦ç»†é”™è¯¯: {error_details}")
            plt.close(fig)
            return {
                'success': False,
                'path': gif_path,
                'error': str(e),
                'error_details': error_details
            }

def load_test_radar_data(data_path, num_samples=12):
    """åŠ è½½æµ‹è¯•é›·è¾¾æ•°æ® - å¢åŠ æ ·æœ¬æ•°é‡ä»¥å±•ç¤ºæ›´å¤šåŠ¨ä½œ"""
    print(f"ğŸ“ åŠ è½½æµ‹è¯•æ•°æ®: {data_path}")
    
    try:
        # å°è¯•åŠ è½½æµ‹è¯•æ•°æ®
        if os.path.exists(data_path):
            test_data = np.load(data_path)
            print(f"âœ… æˆåŠŸåŠ è½½æ•°æ®ï¼Œå½¢çŠ¶: {test_data.shape}")
            
            # ä¸ºäº†è·å¾—æ›´å¤šæ ·åŒ–çš„åŠ¨ä½œï¼Œä»ä¸åŒä½ç½®é‡‡æ ·
            if len(test_data) > num_samples:
                # å‡åŒ€é‡‡æ ·ä»¥è·å¾—æ›´å¤šæ ·åŒ–çš„åŠ¨ä½œ
                indices = np.linspace(0, len(test_data) - 1, num_samples, dtype=int)
                test_data = test_data[indices]
                print(f"âœ… ä» {len(test_data)} ä¸ªæ ·æœ¬ä¸­å‡åŒ€é‡‡æ · {num_samples} ä¸ªï¼Œç´¢å¼•: {indices}")
            
            return test_data
        else:
            print(f"âŒ æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {data_path}")
            print("ğŸ”„ ç”Ÿæˆæ¨¡æ‹Ÿé›·è¾¾æ•°æ®...")
            
            # ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®
            mock_data = np.random.rand(num_samples, 8, 8, 5).astype(np.float32)
            return mock_data
            
    except Exception as e:
        print(f"âŒ åŠ è½½æ•°æ®å¤±è´¥: {e}")
        print("ğŸ”„ ç”Ÿæˆæ¨¡æ‹Ÿé›·è¾¾æ•°æ®...")
        
        # ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®
        mock_data = np.random.rand(num_samples, 8, 8, 5).astype(np.float32)
        return mock_data

def main():
    """ä¸»å‡½æ•°"""
    print("=" * 80)
    print("ğŸš€ éª¨æ¶æå– + GCNé‡æ„å®Œæ•´æµç¨‹")
    print("=" * 80)
    
    # é…ç½®æ–‡ä»¶è·¯å¾„
    extractor_model_path = "mars_transformer_best.pth"
    gcn_model_path = "experiments/gcn_skeleton_memory_optimized/NTU_models/default/ckpt-best.pth"
    gcn_config_path = "cfgs/NTU_models/gcn_skeleton_memory_optimized.yaml"
    
    # æ£€æŸ¥æ–‡ä»¶å­˜åœ¨æ€§
    if not os.path.exists(extractor_model_path):
        print(f"âŒ éª¨æ¶æå–å™¨æƒé‡ä¸å­˜åœ¨: {extractor_model_path}")
        return
        
    if not os.path.exists(gcn_model_path):
        print(f"âŒ GCNé‡æ„å™¨æƒé‡ä¸å­˜åœ¨: {gcn_model_path}")
        return
        
    if not os.path.exists(gcn_config_path):
        print(f"âŒ GCNé…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {gcn_config_path}")
        return
    
    print("âœ… æ‰€æœ‰å¿…éœ€æ–‡ä»¶å­˜åœ¨")
    
    try:
        # åˆ›å»ºæµæ°´çº¿
        print("\\nğŸ—ï¸ åˆå§‹åŒ–å¤„ç†æµæ°´çº¿...")
        pipeline = SkeletonExtractionReconstructionPipeline(
            extractor_model_path, gcn_model_path, gcn_config_path
        )
        
        # åŠ è½½æµ‹è¯•æ•°æ®
        print("\\nğŸ“Š åŠ è½½æµ‹è¯•æ•°æ®...")
        radar_data_path = "/home/uo/myProject/HumanPoint-BERT/data/MARS/featuremap_test.npy"
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        output_dir = "visualizations/skeleton_extraction_reconstruction_new"
        os.makedirs(output_dir, exist_ok=True)
        
        # å¢åŠ æ ·æœ¬æ•°é‡ä»¥å±•ç¤ºæ›´å¤šåŠ¨ä½œ
        num_samples = 12  # å¢åŠ åˆ°12ä¸ªæ ·æœ¬
        test_radar_data = load_test_radar_data(radar_data_path, num_samples=num_samples)
        
        # å¤„ç†æ¯ä¸ªæµ‹è¯•æ ·æœ¬
        print(f"\\nğŸ¯ å¤„ç† {len(test_radar_data)} ä¸ªæµ‹è¯•æ ·æœ¬...")
        
        all_pipeline_results = []
        all_results = []
        
        for i, radar_sample in enumerate(test_radar_data):
            print(f"\\n--- å¤„ç†æ ·æœ¬ {i+1}/{len(test_radar_data)} ---")
            
            # æ‰§è¡Œå®Œæ•´æµç¨‹
            pipeline_result = pipeline.process_complete_pipeline(radar_sample)
            all_pipeline_results.append(pipeline_result)
        
        # ç”Ÿæˆä¸ªåˆ«æ ·æœ¬å¯è§†åŒ–
        print(f"\\nğŸ–¼ï¸ ç”Ÿæˆæ¯ä¸ªæ ·æœ¬çš„å•ç‹¬å¯è§†åŒ–...")
        individual_metrics = pipeline.generate_individual_sample_visualizations(all_pipeline_results, output_dir)
        
        # ç”Ÿæˆå¤šæ ·æœ¬ç»¼åˆå¯è§†åŒ–
        print(f"\\nğŸ¨ ç”Ÿæˆå¤šæ ·æœ¬ç»¼åˆå¯è§†åŒ–...")
        multi_sample_save_path = os.path.join(output_dir, f'multi_sample_skeleton_analysis.png')
        multi_metrics = pipeline.visualize_results(all_pipeline_results, multi_sample_save_path)
        
        # ç”ŸæˆGIFåŠ¨ç”»åºåˆ—
        print(f"\\nğŸ¬ ç”Ÿæˆéª¨æ¶é‡æ„GIFåŠ¨ç”»åºåˆ—...")
        gif_info_list = pipeline.generate_sequence_gif_animations(
            radar_data_path=radar_data_path,
            output_dir=output_dir,
            num_sequences=6,  # ç”Ÿæˆ6ä¸ªGIFåºåˆ—
            frames_per_sequence=6,  # æ¯ä¸ªåºåˆ—6å¸§
            fps=2  # 2å¸§æ¯ç§’ï¼Œè¾ƒæ…¢ä»¥ä¾¿è§‚å¯Ÿç»†èŠ‚
        )
            
        # ä»å¤šæ ·æœ¬æŒ‡æ ‡ä¸­æå–æ¯ä¸ªæ ·æœ¬çš„ç»“æœ
        for i, sample_detail in enumerate(multi_metrics['sample_details']):
            result_summary = {
                'sample_id': int(i + 1),
                'recon_mse_error': float(sample_detail['recon_mse_error']),
                'vq_loss': float(sample_detail['vq_loss']),
                'max_joint_error': float(sample_detail['max_joint_error']),
                'mean_joint_error': float(sample_detail['mean_joint_error']),

            }
            all_results.append(result_summary)
            
            print(f"  ğŸ“Š æ ·æœ¬ {i+1} æŒ‡æ ‡:")
            print(f"     Real Reconstruction MSE: {sample_detail['recon_mse_error']:.6f}")
            print(f"     VQæŸå¤±: {sample_detail['vq_loss']:.6f}")
            print(f"     æœ€å¤§å…³èŠ‚è¯¯å·®: {sample_detail['max_joint_error']:.6f}")
            print(f"     å¹³å‡å…³èŠ‚è¯¯å·®: {sample_detail['mean_joint_error']:.6f}")
        
        # ä¿å­˜æ‰€æœ‰ç»“æœ
        import json
        results_path = os.path.join(output_dir, 'pipeline_results.json')
        with open(results_path, 'w') as f:
            json.dump(all_results, f, indent=2)
        
        # è®¡ç®—æ€»ä½“ç»Ÿè®¡
        print("\\n" + "=" * 80)
        print("ğŸ“ˆ æ€»ä½“ç»Ÿè®¡ç»“æœ:")
        print("=" * 80)
        
        mse_errors = [r['recon_mse_error'] for r in all_results]
        vq_losses = [r['vq_loss'] for r in all_results]
        
        print(f"Average Real Reconstruction MSE: {np.mean(mse_errors):.6f} Â± {np.std(mse_errors):.6f}")
        print(f"Average VQ Loss: {np.mean(vq_losses):.6f} Â± {np.std(vq_losses):.6f}")
        print(f"Best Real Reconstruction MSE: {np.min(mse_errors):.6f}")
        print(f"Worst Real Reconstruction MSE: {np.max(mse_errors):.6f}")
        
        print(f"\\nğŸ“ è¾“å‡ºæ–‡ä»¶:")
        print(f"  ä¸ªåˆ«æ ·æœ¬å¯è§†åŒ–: {len(individual_metrics)} å¼ PNGå›¾ç‰‡")
        print(f"  å¤šæ ·æœ¬ç»¼åˆå›¾: {os.path.basename(multi_sample_save_path)}")  
        print(f"  GIFåŠ¨ç”»åºåˆ—: {len(gif_info_list)} ä¸ªGIFæ–‡ä»¶")
        print(f"  ç»Ÿè®¡ç»“æœ: {os.path.basename(results_path)}")
        print(f"  PNGè¾“å‡ºç›®å½•: {output_dir}/")
        print(f"  GIFè¾“å‡ºç›®å½•: visualizations/skeleton_extraction_gif_reconstruction/")
        
        # æ˜¾ç¤ºç”Ÿæˆçš„å›¾ç‰‡åˆ—è¡¨
        print(f"\\nğŸ–¼ï¸ ç”Ÿæˆçš„å¯è§†åŒ–å›¾ç‰‡:")
        for i, metric in enumerate(individual_metrics):
            print(f"  æ ·æœ¬ {i+1:02d}: extraction_reconstruction_sample_{i+1:02d}.png (æ ‡å‡†åŒ–MSE: {metric['normalized_recon_mse']:.6f})")
        
        # æ˜¾ç¤ºç”Ÿæˆçš„GIFåˆ—è¡¨
        print(f"\\nğŸ¬ ç”Ÿæˆçš„GIFåŠ¨ç”»:")
        for gif_info in gif_info_list:
            if gif_info['success']:
                print(f"  åºåˆ— {gif_info['sequence_id']:02d}: {os.path.basename(gif_info['path'])} "
                      f"(å¸§ {gif_info['start_frame']}-{gif_info['end_frame']}, "
                      f"å¹³å‡æ ‡å‡†åŒ–MSE: {gif_info.get('avg_normalized_mse', 'N/A'):.6f})")
            else:
                print(f"  åºåˆ— {gif_info['sequence_id']:02d}: ç”Ÿæˆå¤±è´¥ - {gif_info.get('error', 'æœªçŸ¥é”™è¯¯')}")
        
        print("\\nğŸ‰ éª¨æ¶æå–+GCNé‡æ„æµç¨‹å®Œæˆï¼")
        
    except Exception as e:
        print(f"\\nâŒ æµç¨‹æ‰§è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()