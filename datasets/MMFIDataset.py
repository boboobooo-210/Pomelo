"""
MMFIæ•°æ®é›†åŠ è½½å™¨ - ä¸“é—¨ç”¨äºVQ-VAEé¢„è®­ç»ƒ
æ”¯æŒåŠ è½½dvae_pretrain.npyæ–‡ä»¶ï¼ˆæ•°æ®å¢å¼ºåçš„é¢„è®­ç»ƒæ•°æ®ï¼‰ï¼Œå¹¶è‡ªåŠ¨åˆ†é…è¯­ä¹‰æ ‡ç­¾
"""

import os
import numpy as np
import torch
from torch.utils.data import Dataset
from .build import DATASETS
from utils.logger import print_log

# 27ä¸ªåŠ¨ä½œçš„è¯­ä¹‰æ ‡ç­¾æ˜ å°„
ACTION_LABELS = {
    'A01': 'Stretching_relaxing',
    'A02': 'Chest_expansion_horizontal', 
    'A03': 'Chest_expansion_vertical',
    'A04': 'Twist_left',
    'A05': 'Twist_right',
    'A06': 'Mark_time',
    'A07': 'Limb_extension_left',
    'A08': 'Limb_extension_right',
    'A09': 'Left_lunge',
    'A10': 'Right_lunge',
    'A11': 'Limb_extension_both',
    'A12': 'Squat',
    'A13': 'Raising_left_hand',
    'A14': 'Raising_right_hand',
    'A15': 'Lunge_toward_left_side',
    'A16': 'Lunge_toward_right_side',
    'A17': 'Waving_left_hand',
    'A18': 'Waving_right_hand',
    'A19': 'Picking_up_things',
    'A20': 'Throwing_toward_left_side',
    'A21': 'Throwing_toward_right_side',
    'A22': 'Kicking_toward_left_side',
    'A23': 'Kicking_toward_right_side',
    'A24': 'Body_extension_left',
    'A25': 'Body_extension_right',
    'A26': 'Jumping_up',
    'A27': 'Bowing'
}

# åŠ¨ä½œIDåˆ°æ•°å­—æ ‡ç­¾çš„æ˜ å°„
ACTION_ID_TO_LABEL = {action_id: idx for idx, action_id in enumerate(sorted(ACTION_LABELS.keys()))}

@DATASETS.register_module(name='MMFI')
class MMFIDataset(Dataset):
    """
    MMFIæ•°æ®é›† - ç”¨äºdVAEè®­ç»ƒçš„éª¨æ¶æ•°æ®
    """
    
    def __init__(self, config):
        self.config = config
        self.data_root = config.DATA_PATH
        self.num_points = getattr(config, 'N_POINTS', 650)  # é»˜è®¤650ç‚¹
        self.subset = getattr(config, 'subset', 'train')
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦é‡é‡‡æ ·ï¼ˆç”¨äºåŸç‰ˆdVAEï¼‰
        self.target_npoints = getattr(config, 'npoints', None)
        if self.target_npoints:
            print(f"ğŸ”„ å°†é‡é‡‡æ ·ç‚¹äº‘ä» {self.num_points} åˆ° {self.target_npoints} ä¸ªç‚¹ï¼ˆç”¨äºåŸç‰ˆdVAEï¼‰")
            self.num_points = self.target_npoints
        
        # æ•°æ®åˆ†å‰²é…ç½®
        self.data_split = {
            'train': {
                'environments': ['E01', 'E02', 'E03'],
                'sessions': 'all',  # E01-E03ä½¿ç”¨æ‰€æœ‰S
                'e04_sessions': ['S31', 'S32']  # E04åªä½¿ç”¨S31å’ŒS32
            },
            'test': {
                'environments': ['E04'],
                'sessions': ['S33', 'S34', 'S35', 'S36']
            },
            'val': {
                'environments': ['E04'], 
                'sessions': ['S37', 'S38', 'S39', 'S40']
            }
        }
        
        # åŠ è½½æ•°æ®
        self.data_list = []
        self.labels = []
        self.action_names = []
        
        self._load_data()
        
        print_log(f"MMFI {self.subset} dataset loaded: {len(self.data_list)} samples", logger='MMFI')
        
    def _load_data(self):
        """åŠ è½½æŒ‡å®šåˆ†å‰²çš„æ•°æ®"""
        split_config = self.data_split[self.subset]
        
        for env in split_config['environments']:
            env_path = os.path.join(self.data_root, env)
            
            if not os.path.exists(env_path):
                continue
                
            # è·å–è¯¥ç¯å¢ƒä¸‹çš„æ‰€æœ‰session
            if env == 'E04':
                # E04çš„sessionæ ¹æ®æ•°æ®é›†åˆ†å‰²æ¥å†³å®š
                sessions = split_config.get('sessions', [])
            elif env in ['E01', 'E02', 'E03'] and self.subset == 'train':
                # è®­ç»ƒæ—¶ï¼ŒE01-E03ä½¿ç”¨æ‰€æœ‰S
                sessions = []
                for item in os.listdir(env_path):
                    if item.startswith('S') and os.path.isdir(os.path.join(env_path, item)):
                        sessions.append(item)
            else:
                # å¯¹äºéè®­ç»ƒé›†ï¼ŒE01-E03ä¸å‚ä¸
                sessions = []
            
            # å¦‚æœæ˜¯è®­ç»ƒé›†ä¸”å½“å‰ç¯å¢ƒæ˜¯E04ï¼Œæ·»åŠ ç‰¹å®šçš„session
            if self.subset == 'train' and env == 'E04':
                sessions.extend(split_config.get('e04_sessions', []))
            
            for session in sessions:
                session_path = os.path.join(env_path, session)
                
                if not os.path.exists(session_path):
                    continue
                    
                # éå†æ‰€æœ‰åŠ¨ä½œ
                for action in sorted(os.listdir(session_path)):
                    if not action.startswith('A'):
                        continue
                        
                    action_path = os.path.join(session_path, action)
                    # ä¼˜å…ˆä½¿ç”¨é¢„è®­ç»ƒæ•°æ®æ–‡ä»¶ï¼ˆæ•°æ®å¢å¼ºåï¼‰ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™ä½¿ç”¨åŸå§‹æ•°æ®
                    pretrain_data_path = os.path.join(action_path, 'dvae_pretrain.npy')
                    ground_truth_path = os.path.join(action_path, 'ground_truth.npy')
                    
                    # é€‰æ‹©å¯ç”¨çš„æ•°æ®æ–‡ä»¶
                    if os.path.exists(pretrain_data_path):
                        data_path = pretrain_data_path
                        data_type = "pretrain"
                    elif os.path.exists(ground_truth_path):
                        data_path = ground_truth_path
                        data_type = "ground_truth"
                    else:
                        continue  # å¦‚æœä¸¤ä¸ªæ–‡ä»¶éƒ½ä¸å­˜åœ¨ï¼Œè·³è¿‡
                    
                    try:
                        # åŠ è½½æ•°æ®æ–‡ä»¶
                        data = np.load(data_path)
                        
                        # æ£€æŸ¥æ•°æ®å½¢çŠ¶
                        if len(data.shape) == 3:
                            frames, points, dims = data.shape
                            print(f"    åŠ è½½: {env}/{session}/{action} - å½¢çŠ¶: {data.shape} ({frames}å¸§ Ã— {points}ç‚¹)")
                            
                            # å°†æ¯ä¸€å¸§ä½œä¸ºç‹¬ç«‹æ ·æœ¬æ·»åŠ åˆ°æ•°æ®é›†
                            for frame_idx in range(frames):
                                frame_data = data[frame_idx]  # å½¢çŠ¶: (650, 3)
                                
                                # è·å–è¯­ä¹‰æ ‡ç­¾
                                action_label = ACTION_ID_TO_LABEL.get(action, 0)
                                action_name = ACTION_LABELS.get(action, 'Unknown')
                                
                                self.data_list.append({
                                    'data': frame_data,
                                    'path': data_path,
                                    'environment': env,
                                    'session': session,
                                    'action': action,
                                    'frame_idx': frame_idx
                                })
                                self.labels.append(action_label)
                                self.action_names.append(action_name)
                        else:
                            print(f"    âš ï¸ è·³è¿‡éæ ‡å‡†æ•°æ®å½¢çŠ¶: {data.shape}")
                            
                    except Exception as e:
                        print_log(f"Error loading {data_path}: {e}", logger='MMFI')
                        continue
    
    def __len__(self):
        return len(self.data_list)
    
    def __getitem__(self, idx):
        """è·å–å•ä¸ªæ ·æœ¬"""
        sample = self.data_list[idx]
        data = sample['data']  # å·²ç»æ˜¯å•å¸§æ•°æ® (650, 3)
        label = self.labels[idx]
        action_name = self.action_names[idx]
        
        # æ•°æ®é¢„å¤„ç†
        data = self._preprocess_data(data)
        
        # ä¸ºäº†ä¸ç°æœ‰æ¡†æ¶å…¼å®¹ï¼Œè¿”å›taxonomy_id, model_id, dataçš„æ ¼å¼
        taxonomy_id = 'human_skeleton'
        model_id = f"mmfi_{sample['environment']}_{sample['session']}_{sample['action']}_f{sample['frame_idx']:03d}_{idx:06d}"
        
        return taxonomy_id, model_id, data
    
    def _preprocess_data(self, data):
        """æ•°æ®é¢„å¤„ç†ï¼šå•å¸§ç‚¹äº‘æ•°æ®"""
        # è½¬æ¢ä¸ºtorch tensor
        if isinstance(data, np.ndarray):
            data = torch.from_numpy(data).float()
        
        # é¦–å…ˆæ£€æŸ¥å¹¶å¤„ç†NaN/Infå€¼
        if torch.isnan(data).any() or torch.isinf(data).any():
            print(f"âš ï¸ å‘ç°NaNæˆ–Infå€¼ï¼Œå°†å…¶æ›¿æ¢ä¸º0")
            data = torch.nan_to_num(data, nan=0.0, posinf=0.0, neginf=0.0)
        
        # æ•°æ®åº”è¯¥å·²ç»æ˜¯ (N, 3) æ ¼å¼çš„ç‚¹äº‘
        if len(data.shape) == 2 and data.shape[1] == 3:
            # ç¡®ä¿ç‚¹æ•°ç¬¦åˆé…ç½®è¦æ±‚
            current_points = data.shape[0]
            target_points = self.num_points
            
            if current_points != target_points:
                # å¦‚æœç‚¹æ•°ä¸åŒ¹é…ï¼Œè¿›è¡Œé‡é‡‡æ ·
                if current_points > target_points:
                    # éšæœºé‡‡æ ·åˆ°ç›®æ ‡ç‚¹æ•°
                    indices = torch.randperm(current_points)[:target_points]
                    data = data[indices]
                else:
                    # é‡å¤é‡‡æ ·åˆ°ç›®æ ‡ç‚¹æ•° - ä½¿ç”¨é‡å¤è€Œä¸æ˜¯éšæœºç´¢å¼•é¿å…è¶…å‡ºèŒƒå›´
                    repeat_times = (target_points + current_points - 1) // current_points
                    data = data.repeat(repeat_times, 1)[:target_points]
            
            # å†æ¬¡æ£€æŸ¥å¤„ç†åçš„æ•°æ®
            if torch.isnan(data).any() or torch.isinf(data).any():
                print(f"âš ï¸ å¤„ç†åä»æœ‰NaNæˆ–Infå€¼ï¼Œä½¿ç”¨é›¶çŸ©é˜µæ›¿æ¢")
                data = torch.zeros_like(data)
            
            # æ•°æ®æ ‡å‡†åŒ–åˆ°åˆç†èŒƒå›´ [-2, 2]
            if data.numel() > 0:
                data_abs_max = torch.abs(data).max()
                if data_abs_max > 5.0:  # å¦‚æœæ•°æ®èŒƒå›´è¿‡å¤§
                    data = data / data_abs_max * 2.0  # å½’ä¸€åŒ–åˆ°[-2, 2]
            
            return data
        else:
            raise ValueError(f"æ•°æ®å½¢çŠ¶é”™è¯¯: {data.shape}ï¼ŒæœŸæœ› (N, 3)")
        
    def get_frame_count_statistics(self):
        """è·å–å¸§æ•°ç»Ÿè®¡ä¿¡æ¯"""
        if not hasattr(self, '_frame_stats'):
            stats = {}
            for sample in self.data_list:
                key = f"{sample['environment']}/{sample['session']}/{sample['action']}"
                if key not in stats:
                    stats[key] = 0
                stats[key] += 1
            self._frame_stats = stats
        return self._frame_stats


