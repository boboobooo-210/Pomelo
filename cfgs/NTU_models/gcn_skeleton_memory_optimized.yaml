# NTU RGB+D 时空图卷积(GCN)骨架Tokenizer训练配置 - 内存优化版本

optimizer: {
  type: AdamW,
  kwargs: {
    lr: 0.0008,  # 适当降低学习率适应小批量
    weight_decay: 0.0001
  }
}

scheduler: {
  type: CosLR,
  kwargs: {
    epochs: 100,   # 减少epoch数便于测试
    initial_epochs: 5,
    warming_up_init_lr: 0.0001
  }
}

# KL散度权重配置（用于VQ-VAE损失）
# 注意：这里的权重是 VQ loss 的系数，不是真正的 KL 散度
# 需要足够大才能迫使编码器学习有意义的离散表示
kldweight: {
  start: 0.5,   # 从一开始就给一定权重，避免编码器学到"懒惰"的捷径
  target: 2.0,  # 最终权重设为2.0，让VQ loss比重构损失更重要
  ntime: 2000   # 2000步内达到目标权重
}

# 数据集配置 - 内存优化
dataset: {
  train: { 
    _base_: cfgs/dataset_configs/NTU_skeleton_raw.yaml, 
    others: {
      subset: 'train',
      npoints: 25,
      normalize: true,
      bs: 4  # 减小批大小节省内存
    }
  },
  val: { 
    _base_: cfgs/dataset_configs/NTU_skeleton_raw.yaml, 
    others: {
      subset: 'val',
      npoints: 25,
      normalize: true,
      bs: 4
    }
  },
  test: {
    _base_: cfgs/dataset_configs/NTU_skeleton_raw.yaml,
    others: {
      subset: 'test',
      npoints: 25,
      normalize: true,
      bs: 4
    }
  }
}

# GCN骨架Tokenizer配置 - 集成分组损失和关节权重
model: {
  NAME: GCNSkeletonTokenizer,
  num_joints: 25,
  num_tokens: 640,  # 5个语义组 × 128码字/组 = 640个码字
  token_dim: 256,
  temporal_length: 1
}

# 训练设置 - 内存优化
total_bs: 8         # 通过梯度累积达到等效批大小
step_per_update: 2  # 梯度累积2步 (4*2=8)
max_epoch: 100       # 减少epoch数
use_gpu: true
val_freq: 10        # 减少验证频率节省时间
num_workers: 2      # 减少数据加载进程
seed: 2021
consider_metric: CDL1
